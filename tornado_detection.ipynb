{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saratutuianu/Tornado-detection-using-radar-images/blob/main/tornado_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "uUGxjPZr6nM5",
        "outputId": "bd55a4f3-e147-4d4c-9139-5a2c64be9082"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras>=3.0 in /usr/local/lib/python3.12/dist-packages (from -r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 2)) (3.10.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from -r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from -r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 6)) (0.23.0+cu126)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.12/dist-packages (from -r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 13)) (1.8.1)\n",
            "Requirement already satisfied: lightning in /usr/local/lib/python3.12/dist-packages (from -r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 14)) (2.5.3)\n",
            "Requirement already satisfied: numpy~=1.26.0 in /usr/local/lib/python3.12/dist-packages (from -r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 2)) (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from -r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 3)) (3.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from -r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 4)) (2.2.2)\n",
            "Requirement already satisfied: xarray in /usr/local/lib/python3.12/dist-packages (from -r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 5)) (2025.8.0)\n",
            "Requirement already satisfied: netCDF4~=1.6.0 in /usr/local/lib/python3.12/dist-packages (from -r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 6)) (1.6.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from -r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 7)) (4.67.1)\n",
            "Requirement already satisfied: glob2 in /usr/local/lib/python3.12/dist-packages (from -r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 8)) (0.7)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.12/dist-packages (from -r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 9)) (8.4.1)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.12/dist-packages (from -r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (1.1.1)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from -r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 15)) (0.34.4)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from keras>=3.0->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 2)) (1.4.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.0->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 2)) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.0->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 2)) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from keras>=3.0->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 2)) (3.14.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.0->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 2)) (0.17.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.12/dist-packages (from keras>=3.0->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 2)) (0.5.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from keras>=3.0->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 2)) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (4.14.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (3.4.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 6)) (11.3.0)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 13)) (0.15.2)\n",
            "Requirement already satisfied: PyYAML<8.0,>5.4 in /usr/local/lib/python3.12/dist-packages (from lightning->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 14)) (6.0.2)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.12/dist-packages (from lightning->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 14)) (2.5.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 3)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 3)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 3)) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 3)) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 3)) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 3)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 4)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 4)) (2025.2)\n",
            "Requirement already satisfied: cftime in /usr/local/lib/python3.12/dist-packages (from netCDF4~=1.6.0->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 6)) (1.6.4.post1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from netCDF4~=1.6.0->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 6)) (2025.8.3)\n",
            "Requirement already satisfied: iniconfig>=1 in /usr/local/lib/python3.12/dist-packages (from pytest->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 9)) (2.1.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.12/dist-packages (from pytest->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 9)) (1.6.0)\n",
            "Requirement already satisfied: pygments>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from pytest->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 9)) (2.19.2)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.12/dist-packages (from jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (6.5.7)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.12/dist-packages (from jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (6.1.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.12/dist-packages (from jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (7.16.6)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.12/dist-packages (from jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (6.17.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.12/dist-packages (from jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (7.7.1)\n",
            "Requirement already satisfied: jupyterlab in /usr/local/lib/python3.12/dist-packages (from jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (4.4.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 15)) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 15)) (1.1.7)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<2027.0,>=2022.5.0->lightning->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 14)) (3.12.15)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 3)) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (1.8.15)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (7.4.9)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (26.2.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (6.4.2)\n",
            "Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (5.7.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (3.0.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (3.0.2)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-console->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (3.0.51)\n",
            "Requirement already satisfied: async-lru>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (2.0.5)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.28.1)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.12/dist-packages (from jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (5.8.1)\n",
            "Requirement already satisfied: jupyter-lsp>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (2.2.6)\n",
            "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (2.17.0)\n",
            "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in /usr/local/lib/python3.12/dist-packages (from jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (2.27.3)\n",
            "Requirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.12/dist-packages (from jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (4.13.4)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.10.2)\n",
            "Requirement already satisfied: nbformat>=5.7 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (5.10.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (1.5.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (25.1.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.22.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (1.3.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 15)) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 15)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 15)) (2.5.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.0->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 2)) (4.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 14)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 14)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 14)) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 14)) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 14)) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 14)) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 14)) (1.20.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (1.4.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.16.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (4.9.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.4)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core->jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (4.3.8)\n",
            "Requirement already satisfied: jupyter-events>=0.11.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.12.0)\n",
            "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.5.3)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (1.8.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.12/dist-packages (from argon2-cffi->notebook->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (25.1.0)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.12/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (2.17.0)\n",
            "Requirement already satisfied: json5>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.12.1)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (4.25.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 2)) (0.1.2)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat>=5.7->nbconvert->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (2.21.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.2.13)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.12/dist-packages (from terminado>=0.8.3->notebook->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.7.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->nbconvert->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (2.7)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.25.0->jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (1.3.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.8.4)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.27.0)\n",
            "Requirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (3.3.0)\n",
            "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.1.4)\n",
            "Requirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.1.1)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (2.22)\n",
            "Requirement already satisfied: fqdn in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (1.5.1)\n",
            "Requirement already satisfied: isoduration in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (20.11.0)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (3.0.0)\n",
            "Requirement already satisfied: rfc3987-syntax>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (1.1.0)\n",
            "Requirement already satisfied: uri-template in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (1.3.0)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (24.11.1)\n",
            "Requirement already satisfied: lark>=1.2.2 in /usr/local/lib/python3.12/dist-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (1.2.2)\n",
            "Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (1.3.0)\n",
            "Requirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.12/dist-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (2.9.0.20250822)\n"
          ]
        }
      ],
      "source": [
        "!pip install -r ./drive/MyDrive/proiect_ml/requirements/torch.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0b0tMziB5_b"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "sys.path.append('/content/drive/MyDrive/proiect_ml')\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import importlib, linecache\n",
        "\n",
        "import torch\n",
        "from torch import optim, nn\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms, utils\n",
        "\n",
        "import tornet.data.preprocess as preprocess\n",
        "\n",
        "linecache.checkcache(preprocess.__file__)      # invalidează cache-ul de linii\n",
        "preprocess = importlib.reload(preprocess)\n",
        "\n",
        "from tornet.data.loader import read_file, TornadoDataLoader\n",
        "from tornet.data.preprocess import add_coordinates, permute_dims, remove_tilt_dim, get_shape\n",
        "from tornet.data.constants import ALL_VARIABLES\n",
        "\n",
        "data_root=r'./drive/MyDrive/proiect_ml/tornet_dataset'\n",
        "\n",
        "year = 2019\n",
        "\n",
        "catalog_path = os.path.join(data_root,'catalog.csv')\n",
        "\n",
        "catalog = pd.read_csv(catalog_path,parse_dates=['start_time','end_time'])\n",
        "\n",
        "catalog['J'] = catalog['start_time'].dt.dayofyear\n",
        "catalog['r'] = catalog['J'] % 20\n",
        "catalog = catalog[catalog.start_time.dt.year == 2019]\n",
        "\n",
        "catalog_test = catalog[catalog['type'] == 'test']\n",
        "catalog_test = catalog_test.sample(frac=1,random_state=1234) # shuffles list\n",
        "\n",
        "catalog = catalog[catalog['type']=='train']\n",
        "\n",
        "catalog_train = catalog[catalog['r'] <= 13]\n",
        "catalog_train = catalog_train.sample(frac=1,random_state=1234) # shuffles list\n",
        "\n",
        "catalog_validation = catalog[(catalog['r'] > 13) & (catalog['r'] < 17)]\n",
        "catalog_validation = catalog_validation.sample(frac=1,random_state=1234) # shuffles list\n",
        "\n",
        "confirmed_number = len(catalog_train[catalog_train['category'] == 'TOR'])\n",
        "total_number = len(catalog_train)\n",
        "\n",
        "class TornadoDataset(TornadoDataLoader,Dataset):\n",
        "    pass\n",
        "\n",
        "transform = transforms.Compose([\n",
        "            lambda d: remove_tilt_dim(d)\n",
        "            ])\n",
        "\n",
        "file_list_train = [os.path.join(data_root,f) for f in catalog_train.filename]\n",
        "file_list_validation = [os.path.join(data_root,f) for f in catalog_validation.filename]\n",
        "file_list_test = [os.path.join(data_root,f) for f in catalog_test.filename]\n",
        "\n",
        "torch_ds_train = TornadoDataset(file_list_train,\n",
        "                          variables=ALL_VARIABLES,\n",
        "                          n_frames=4,\n",
        "                          tilt_last=False, # so ordering of dims is [time,tilt,az,range]\n",
        "                          transform=transform)\n",
        "torch_ds_validation = TornadoDataset(file_list_validation,\n",
        "                          variables=ALL_VARIABLES,\n",
        "                          n_frames=4,\n",
        "                          tilt_last=False, # so ordering of dims is [time,tilt,az,range]\n",
        "                          transform=transform)\n",
        "torch_ds_test = TornadoDataset(file_list_test,\n",
        "                          variables=ALL_VARIABLES,\n",
        "                          n_frames=4,\n",
        "                          tilt_last=False, # so ordering of dims is [time,tilt,az,range]\n",
        "                          transform=transform)\n",
        "\n",
        "\n",
        "batch_size=16\n",
        "\n",
        "torch_dl_train = torch.utils.data.DataLoader( torch_ds_train,\n",
        "                                        batch_size=batch_size,\n",
        "                                        num_workers=8 )\n",
        "\n",
        "torch_dl_validation = torch.utils.data.DataLoader( torch_ds_validation,\n",
        "                                        batch_size=batch_size,\n",
        "                                        num_workers=8 )\n",
        "\n",
        "torch_dl_test = torch.utils.data.DataLoader( torch_ds_test,\n",
        "                                        batch_size=batch_size,\n",
        "                                        num_workers=8 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTh_wMXVO3ld"
      },
      "outputs": [],
      "source": [
        "from tornet.models.torch.cnn_baseline import NormalizeVariable\n",
        "from tornet.data.constants import CHANNEL_MIN_MAX\n",
        "\n",
        "def conv3d_bn_block(in_channels, out_channels, kernel_size=3, stride=1, padding='same'):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv3d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
        "        nn.BatchNorm3d(out_channels),\n",
        "        nn.ReLU(inplace=True)\n",
        "    )\n",
        "\n",
        "def conv3d_transpose_bn_block(in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
        "    return nn.Sequential(\n",
        "        nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
        "    )\n",
        "\n",
        "class TornadoLikelihood(nn.Module):\n",
        "    def __init__(self,radar_variables=ALL_VARIABLES):\n",
        "      super(TornadoLikelihood, self).__init__()\n",
        "      self.radar_variables=radar_variables\n",
        "\n",
        "      # Partea de encoder\n",
        "      self.conv_layer_encoder1 = conv3d_bn_block(in_channels=len(radar_variables), out_channels=16)\n",
        "      self.conv_layer_encoder2 = conv3d_bn_block(in_channels=16, out_channels=16)\n",
        "\n",
        "      self.max_pool_encoder1 = nn.MaxPool3d(kernel_size=(1,2,2), stride=(1,2,2))\n",
        "\n",
        "      self.conv_layer_encoder3 = conv3d_bn_block(in_channels=16, out_channels=32)\n",
        "      self.conv_layer_encoder4 = conv3d_bn_block(in_channels=32, out_channels=32)\n",
        "\n",
        "      self.max_pool_encoder2 = nn.MaxPool3d(kernel_size=(1,2,2), stride=(1,2,2))\n",
        "\n",
        "      self.conv_layer_encoder5 = conv3d_bn_block(in_channels=32, out_channels=64)\n",
        "      self.conv_layer_encoder6 = conv3d_bn_block(in_channels=64, out_channels=64)\n",
        "\n",
        "      self.max_pool_encoder3 = nn.MaxPool3d(kernel_size=2, stride=2)\n",
        "\n",
        "      self.conv_layer_encoder7 = conv3d_bn_block(in_channels=64, out_channels=128)\n",
        "      self.conv_layer_encoder8 = conv3d_bn_block(in_channels=128, out_channels=128)\n",
        "\n",
        "      self.max_pool_encoder4 = nn.MaxPool3d(kernel_size=2, stride=2)\n",
        "\n",
        "      # Partea de decoder\n",
        "      self.conv_layer_decoder1 = conv3d_bn_block(in_channels=128, out_channels=128)\n",
        "      self.conv_layer_decoder2 = conv3d_bn_block(in_channels=128, out_channels=128)\n",
        "\n",
        "      self.upsample_decoder1 = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)\n",
        "\n",
        "      self.conv_layer_decoder3 = conv3d_bn_block(in_channels=128, out_channels=64)\n",
        "      self.conv_layer_decoder4 = conv3d_bn_block(in_channels=64, out_channels=64)\n",
        "\n",
        "      self.upsample_decoder2 = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)\n",
        "\n",
        "      self.conv_layer_decoder5 = conv3d_bn_block(in_channels=64, out_channels=32)\n",
        "      self.conv_layer_decoder6 = conv3d_bn_block(in_channels=32, out_channels=32)\n",
        "\n",
        "      self.upsample_decoder3 = nn.Upsample(scale_factor=(1,2,2), mode='trilinear', align_corners=True)\n",
        "\n",
        "      self.conv_layer_decoder7 = conv3d_bn_block(in_channels=32, out_channels=16)\n",
        "      self.conv_layer_decoder8 = conv3d_bn_block(in_channels=16, out_channels=16)\n",
        "\n",
        "      self.upsample_decoder4 = nn.Upsample(scale_factor=(1,2,2), mode='trilinear', align_corners=True)\n",
        "\n",
        "      self.conv_layer_final = conv3d_transpose_bn_block(in_channels=16, out_channels=1)\n",
        "\n",
        "    def _normalize_inputs(self,data):\n",
        "        normed_data = {}\n",
        "        for v in self.radar_variables:\n",
        "            min_max = np.array(CHANNEL_MIN_MAX[v]) # [2,]\n",
        "            scale = 1/(min_max[1]-min_max[0])\n",
        "            offset = min_max[0]\n",
        "            normed_data[v] = (data[v] - offset) * scale\n",
        "\n",
        "        return normed_data\n",
        "\n",
        "    def forward(self,x):\n",
        "      \"\"\"\n",
        "      Assumes x contains radar varialbes on [batch,tilt,az,rng]\n",
        "      \"\"\"\n",
        "      # extract radar inputs\n",
        "      x = {v:x[v] for v in self.radar_variables} # each [batch,time,Az,Rng]\n",
        "      # normalize\n",
        "      x = self._normalize_inputs(x) # each [batch,time,Az,Rng]\n",
        "      # concatenate along channel (time) dim\n",
        "      x = torch.stack([x[v] for v in self.radar_variables], dim=1)\n",
        "\n",
        "      x = torch.where(torch.isnan(x),-3,x)\n",
        "\n",
        "      x = self.conv_layer_encoder1(x)\n",
        "      x = self.conv_layer_encoder2(x)\n",
        "      x = self.max_pool_encoder1(x)\n",
        "\n",
        "      x = self.conv_layer_encoder3(x)\n",
        "      x = self.conv_layer_encoder4(x)\n",
        "      x = self.max_pool_encoder2(x)\n",
        "\n",
        "      x = self.conv_layer_encoder5(x)\n",
        "      x = self.conv_layer_encoder6(x)\n",
        "      x = self.max_pool_encoder3(x)\n",
        "\n",
        "      x = self.conv_layer_encoder7(x)\n",
        "      x = self.conv_layer_encoder8(x)\n",
        "      x = self.max_pool_encoder4(x)\n",
        "\n",
        "      x = self.conv_layer_decoder1(x)\n",
        "      x = self.conv_layer_decoder2(x)\n",
        "      x = self.upsample_decoder1(x)\n",
        "\n",
        "      x = self.conv_layer_decoder3(x)\n",
        "      x = self.conv_layer_decoder4(x)\n",
        "      x = self.upsample_decoder2(x)\n",
        "\n",
        "      x = self.conv_layer_decoder5(x)\n",
        "      x = self.conv_layer_decoder6(x)\n",
        "      x = self.upsample_decoder3(x)\n",
        "\n",
        "      x = self.conv_layer_decoder7(x)\n",
        "      x = self.conv_layer_decoder8(x)\n",
        "      x = self.upsample_decoder4(x)\n",
        "\n",
        "      x = self.conv_layer_final(x)\n",
        "\n",
        "      return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KwrKOwlw8Urj"
      },
      "outputs": [],
      "source": [
        "import torchmetrics\n",
        "from torchmetrics.functional.classification import binary_auroc, binary_average_precision\n",
        "\n",
        "def accuracy(logits, y):\n",
        "  correct = 0\n",
        "  for i in range(len(logits)):\n",
        "    if logits[i] >= 0.24 and y[i] == 1:\n",
        "      correct += 1\n",
        "    elif logits[i] < 0.24 and y[i] == 0:\n",
        "      correct += 1\n",
        "\n",
        "  return correct / float(len(y)) * 100.0\n",
        "\n",
        "def recall(logits, y):\n",
        "  correct = 0\n",
        "  false_negatives = 0\n",
        "  for i in range(len(logits)):\n",
        "    if logits[i] >= 0.24 and y[i] == 1:\n",
        "      correct += 1\n",
        "    elif logits[i] < 0.24 and y[i] == 1:\n",
        "      false_negatives += 1\n",
        "\n",
        "  return 0.0 if correct + false_negatives == 0 else correct / (correct + false_negatives) * 100.0\n",
        "\n",
        "def precision(logits, y):\n",
        "  correct = 0\n",
        "  false_positives = 0\n",
        "  for i in range(len(logits)):\n",
        "    if logits[i] >= 0.24 and y[i] == 1:\n",
        "      correct += 1\n",
        "    elif logits[i] >= 0.24 and y[i] == 0:\n",
        "      false_positives += 1\n",
        "\n",
        "  return 0.0 if correct + false_positives == 0 else correct / (correct + false_positives) * 100.0\n",
        "\n",
        "def f1_score(logits, y):\n",
        "  p = precision(logits, y)\n",
        "  r = recall(logits, y)\n",
        "  return 0.0 if p + r == 0 else 2 * (p * r) / (p + r)\n",
        "\n",
        "def apply_metrics(logits, y):\n",
        "  print(f\"Accuracy: , {accuracy(logits, y):.4f}\")\n",
        "  print(f\"Recall: , {recall(logits, y):.4f}\")\n",
        "  print(f\"Precision: , {precision(logits, y):.4f}\")\n",
        "  print(f\"F1 Score: , {f1_score(logits, y):.4f}\")\n",
        "  print(f\"AUROC:  {binary_auroc(logits, y).item():.4f}\")\n",
        "  print(f\"AUPRC:  {binary_average_precision(logits, y).item():.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JIJRviy1KmYa"
      },
      "outputs": [],
      "source": [
        "def RMSprop(index, gamma, dw, db, vdw, vdb, learning_rate):\n",
        "    vdw = gamma * vdw + (1 - gamma) * dw ** 2\n",
        "    vdb = gamma * vdb + (1 - gamma) * db ** 2\n",
        "\n",
        "    model.layers[index].weight -= (learning_rate / (np.sqrt(vdw + 1e-08))) * dw\n",
        "    model.layers[index].bias -= (learning_rate / (np.sqrt(vdb + 1e-08))) * db"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-Ii192qVskex",
        "outputId": "f354589f-11fb-4f42-ee24-94e82fdc8ae0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reluare din /content/drive/MyDrive/proiect_ml/checkpoints/epoch_002.pth | start_epoch=2 | best_val=1.2577\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7c47945f0900>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            "    self._shutdown_workers()Exception ignored in: \n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x7c47945f0900>Exception ignored in: \n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            "Traceback (most recent call last):\n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x7c47945f0900>  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            "    \n",
            "if w.is_alive():Traceback (most recent call last):\n",
            "    \n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            "self._shutdown_workers() \n",
            "   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            "     self._shutdown_workers()    \n",
            " if w.is_alive():  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            "\n",
            "      if w.is_alive():  \n",
            "^  ^ ^  ^  ^   ^ ^ ^^ ^^^^^^^^^^^^^^^\n",
            "^^^^^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^^^    ^^assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "\n",
            "^     \n",
            " assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            " \n",
            "     assert self._parent_pid == os.getpid(), 'can only test a child process' \n",
            "                          ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^^AssertionError^^^: ^^can only test a child process^^\n",
            "\n",
            "^^AssertionError: ^can only test a child process^Exception ignored in: \n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x7c47945f0900>^^\n",
            "^Traceback (most recent call last):\n",
            "^Exception ignored in:   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            "\n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x7c47945f0900>    AssertionError\n",
            "self._shutdown_workers(): Traceback (most recent call last):\n",
            "can only test a child process\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            "\n",
            "        self._shutdown_workers()if w.is_alive():\n",
            "Exception ignored in: \n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            "Exception ignored in:  <function _MultiProcessingDataLoaderIter.__del__ at 0x7c47945f0900>    \n",
            " <function _MultiProcessingDataLoaderIter.__del__ at 0x7c47945f0900> if w.is_alive():Traceback (most recent call last):\n",
            "\n",
            "\n",
            " Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            "    File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            "           self._shutdown_workers() self._shutdown_workers()\n",
            "    File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            "\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            "         if w.is_alive(): \n",
            "^if w.is_alive(): ^ ^ ^ \n",
            "^ ^^ ^ ^^^^^ ^^^^ ^^^^ ^^^ ^\n",
            " ^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^ ^^    ^ ^assert self._parent_pid == os.getpid(), 'can only test a child process'^^^\n",
            "^^^ ^\n",
            "\n",
            " ^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            " ^         ^assert self._parent_pid == os.getpid(), 'can only test a child process' assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            "\n",
            "  ^  ^    ^  ^  ^     ^\n",
            " ^   File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "      ^ ^  ^assert self._parent_pid == os.getpid(), 'can only test a child process' ^\n",
            " ^  ^ ^ ^^^^^^^^ ^^^^ ^^^ ^^ ^^^^ ^^^ ^ ^^^^ ^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^^^^^^^^^^AssertionError\n",
            "^^: ^AssertionError^^^: can only test a child process^^can only test a child process\n",
            "^\n",
            "\n",
            "^AssertionError^^: ^can only test a child process\n",
            "^^\n",
            "AssertionError: Exception ignored in: can only test a child process\n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x7c47945f0900>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            "Exception ignored in:     <function _MultiProcessingDataLoaderIter.__del__ at 0x7c47945f0900>self._shutdown_workers()\n",
            "\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            "Traceback (most recent call last):\n",
            "      File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            "if w.is_alive():    \n",
            "self._shutdown_workers() \n",
            "   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            "      if w.is_alive(): \n",
            "    ^^^  ^ ^ ^ ^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "        assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "\n",
            "                    ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^Exception ignored in: ^^Exception ignored in: ^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7c47945f0900><function _MultiProcessingDataLoaderIter.__del__ at 0x7c47945f0900>^^\n",
            "\n",
            "^^Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "^^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            "^^        ^^self._shutdown_workers()^self._shutdown_workers()^\n",
            "^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            "^^    ^    ^if w.is_alive():^\n",
            "if w.is_alive():^^\n",
            "^^  ^^ ^ ^\n",
            "  ^AssertionError  ^ :  can only test a child process\n",
            "  \n",
            "AssertionError Exception ignored in:  : ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7c47945f0900>^can only test a child process^\n",
            "^^\n",
            "Traceback (most recent call last):\n",
            "^^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            "Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7c47945f0900>^    ^^self._shutdown_workers()\n",
            "^\n",
            "^^^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            "^Traceback (most recent call last):\n",
            "^    ^^if w.is_alive():  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            "^^\n",
            "^    ^ ^ \n",
            "self._shutdown_workers()\n",
            "   File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "           File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            " assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'     \n",
            "\n",
            "if w.is_alive():   \n",
            "^ ^ ^   ^   ^    ^    ^  ^  ^   ^    ^^^^^^^^^^^^^\n",
            "^^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^^^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^^^^^\n",
            "^^^ ^^^ ^^ ^^^ ^^ \n",
            "^^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            " ^^    ^^ assert self._parent_pid == os.getpid(), 'can only test a child process'^^^\n",
            " ^^   ^^ ^^  ^^^ ^^ ^^^ ^^^ ^^^ ^^^ ^ ^^^ ^^^^^^^^^^^^^^\n",
            "^^^AssertionError^^: ^^^can only test a child process\n",
            "^^^^AssertionError^^\n",
            "^: ^can only test a child process^^\n",
            "^^^^Exception ignored in: ^Exception ignored in: ^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7c47945f0900>^\n",
            "^^Traceback (most recent call last):\n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x7c47945f0900>^^^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            "\n",
            "^^    ^Traceback (most recent call last):\n",
            "^self._shutdown_workers()^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            "^\n",
            "    ^self._shutdown_workers()  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            "^^^^^\n",
            "\n",
            "    ^AssertionError  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            "if w.is_alive():: ^\n",
            "    can only test a child process^if w.is_alive():^\n",
            " \n",
            "^  ^ ^  ^  Exception ignored in: \n",
            "  <function _MultiProcessingDataLoaderIter.__del__ at 0x7c47945f0900>AssertionError :  ^\n",
            " can only test a child process^ \n",
            "Traceback (most recent call last):\n",
            "^^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            "^^    ^^^^self._shutdown_workers()^^\n",
            "^^^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            "^^    ^^^^if w.is_alive():\n",
            "\n",
            "   File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^     ^^ assert self._parent_pid == os.getpid(), 'can only test a child process' \n",
            "\n",
            "    File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "        ^assert self._parent_pid == os.getpid(), 'can only test a child process' \n",
            "^   ^ ^  ^  ^  ^ ^ ^  ^ ^^ ^^ \n",
            " ^^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^    ^^^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
            "^^^ ^^ ^^ ^^^ ^^  ^^^^ ^ ^^^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^AssertionError^^: ^^^can only test a child process^^\n",
            "^\n",
            "AssertionError: can only test a child process\n",
            "^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/15], Step [10/1030], Loss: 1.7924\n",
            "Epoch [3/15], Step [20/1030], Loss: 1.0609\n",
            "Epoch [3/15], Step [30/1030], Loss: 0.6949\n",
            "Epoch [3/15], Step [40/1030], Loss: 2.1582\n",
            "Epoch [3/15], Step [50/1030], Loss: 2.1582\n",
            "Epoch [3/15], Step [60/1030], Loss: 1.0607\n",
            "Epoch [3/15], Step [70/1030], Loss: 1.0608\n",
            "Epoch [3/15], Step [80/1030], Loss: 1.4268\n",
            "Epoch [3/15], Step [90/1030], Loss: 1.4272\n",
            "Epoch [3/15], Step [100/1030], Loss: 1.4273\n",
            "Epoch [3/15], Step [110/1030], Loss: 1.4277\n",
            "Epoch [3/15], Step [120/1030], Loss: 1.4271\n",
            "Epoch [3/15], Step [130/1030], Loss: 1.4268\n",
            "Epoch [3/15], Step [140/1030], Loss: 1.0602\n",
            "Epoch [3/15], Step [150/1030], Loss: 1.0230\n",
            "Epoch [3/15], Step [160/1030], Loss: 0.4553\n",
            "Epoch [3/15], Step [170/1030], Loss: 1.1225\n",
            "Epoch [3/15], Step [180/1030], Loss: 1.5032\n",
            "Epoch [3/15], Step [190/1030], Loss: 1.4370\n",
            "Epoch [3/15], Step [200/1030], Loss: 1.8410\n",
            "Epoch [3/15], Step [210/1030], Loss: 1.4495\n",
            "Epoch [3/15], Step [220/1030], Loss: 0.6442\n",
            "Epoch [3/15], Step [230/1030], Loss: 1.4521\n",
            "Epoch [3/15], Step [240/1030], Loss: 0.6363\n",
            "Epoch [3/15], Step [250/1030], Loss: 0.6376\n",
            "Epoch [3/15], Step [260/1030], Loss: 1.4510\n",
            "Epoch [3/15], Step [270/1030], Loss: 1.0412\n",
            "Epoch [3/15], Step [280/1030], Loss: 1.4522\n",
            "Epoch [3/15], Step [290/1030], Loss: 1.4446\n",
            "Epoch [3/15], Step [300/1030], Loss: 1.8201\n",
            "Epoch [3/15], Step [310/1030], Loss: 1.7562\n",
            "Epoch [3/15], Step [320/1030], Loss: 0.7125\n",
            "Epoch [3/15], Step [330/1030], Loss: 1.0673\n",
            "Epoch [3/15], Step [340/1030], Loss: 1.4222\n",
            "Epoch [3/15], Step [350/1030], Loss: 1.4286\n",
            "Epoch [3/15], Step [360/1030], Loss: 1.0627\n",
            "Epoch [3/15], Step [370/1030], Loss: 1.0769\n",
            "Epoch [3/15], Step [380/1030], Loss: 1.0616\n",
            "Epoch [3/15], Step [390/1030], Loss: 1.4287\n",
            "Epoch [3/15], Step [400/1030], Loss: 1.0581\n",
            "Epoch [3/15], Step [410/1030], Loss: 1.0515\n",
            "Epoch [3/15], Step [420/1030], Loss: 1.4423\n",
            "Epoch [3/15], Step [430/1030], Loss: 1.4384\n",
            "Epoch [3/15], Step [440/1030], Loss: 1.1010\n",
            "Epoch [3/15], Step [450/1030], Loss: 1.0580\n",
            "Epoch [3/15], Step [460/1030], Loss: 2.1739\n",
            "Epoch [3/15], Step [470/1030], Loss: 2.5030\n",
            "Epoch [3/15], Step [480/1030], Loss: 1.4151\n",
            "Epoch [3/15], Step [490/1030], Loss: 1.7463\n",
            "Epoch [3/15], Step [500/1030], Loss: 1.4104\n",
            "Epoch [3/15], Step [510/1030], Loss: 1.1120\n",
            "Epoch [3/15], Step [520/1030], Loss: 2.0785\n",
            "Epoch [3/15], Step [530/1030], Loss: 1.7407\n",
            "Epoch [3/15], Step [540/1030], Loss: 1.3876\n",
            "Epoch [3/15], Step [550/1030], Loss: 1.7444\n",
            "Epoch [3/15], Step [560/1030], Loss: 0.7555\n",
            "Epoch [3/15], Step [570/1030], Loss: 1.3814\n",
            "Epoch [3/15], Step [580/1030], Loss: 1.7539\n",
            "Epoch [3/15], Step [590/1030], Loss: 1.0838\n",
            "Epoch [3/15], Step [600/1030], Loss: 2.1568\n",
            "Epoch [3/15], Step [610/1030], Loss: 1.0501\n",
            "Epoch [3/15], Step [620/1030], Loss: 1.4388\n",
            "Epoch [3/15], Step [630/1030], Loss: 1.0779\n",
            "Epoch [3/15], Step [640/1030], Loss: 1.0521\n",
            "Epoch [3/15], Step [650/1030], Loss: 1.4216\n",
            "Epoch [3/15], Step [660/1030], Loss: 1.4260\n",
            "Epoch [3/15], Step [670/1030], Loss: 1.7768\n",
            "Epoch [3/15], Step [680/1030], Loss: 1.0660\n",
            "Epoch [3/15], Step [690/1030], Loss: 0.7151\n",
            "Epoch [3/15], Step [700/1030], Loss: 1.4432\n",
            "Epoch [3/15], Step [710/1030], Loss: 1.0459\n",
            "Epoch [3/15], Step [720/1030], Loss: 1.4379\n",
            "Epoch [3/15], Step [730/1030], Loss: 1.0348\n",
            "Epoch [3/15], Step [740/1030], Loss: 0.6825\n",
            "Epoch [3/15], Step [750/1030], Loss: 1.0618\n",
            "Epoch [3/15], Step [760/1030], Loss: 2.1786\n",
            "Epoch [3/15], Step [770/1030], Loss: 2.1090\n",
            "Epoch [3/15], Step [780/1030], Loss: 1.7624\n",
            "Epoch [3/15], Step [790/1030], Loss: 2.0910\n",
            "Epoch [3/15], Step [800/1030], Loss: 0.7334\n",
            "Epoch [3/15], Step [810/1030], Loss: 1.0773\n",
            "Epoch [3/15], Step [820/1030], Loss: 1.0667\n",
            "Epoch [3/15], Step [830/1030], Loss: 1.0554\n",
            "Epoch [3/15], Step [840/1030], Loss: 1.0616\n",
            "Epoch [3/15], Step [850/1030], Loss: 1.7942\n",
            "Epoch [3/15], Step [860/1030], Loss: 0.6987\n",
            "Epoch [3/15], Step [870/1030], Loss: 1.7999\n",
            "Epoch [3/15], Step [880/1030], Loss: 1.8056\n",
            "Epoch [3/15], Step [890/1030], Loss: 1.8012\n",
            "Epoch [3/15], Step [900/1030], Loss: 1.0593\n",
            "Epoch [3/15], Step [910/1030], Loss: 0.6835\n",
            "Epoch [3/15], Step [920/1030], Loss: 1.4234\n",
            "Epoch [3/15], Step [930/1030], Loss: 1.4222\n",
            "Epoch [3/15], Step [940/1030], Loss: 1.0661\n",
            "Epoch [3/15], Step [950/1030], Loss: 1.7752\n",
            "Epoch [3/15], Step [960/1030], Loss: 1.4266\n",
            "Epoch [3/15], Step [970/1030], Loss: 1.0568\n",
            "Epoch [3/15], Step [980/1030], Loss: 0.6799\n",
            "Epoch [3/15], Step [990/1030], Loss: 1.4329\n",
            "Epoch [3/15], Step [1000/1030], Loss: 1.0923\n",
            "Epoch [3/15], Step [1010/1030], Loss: 0.6946\n",
            "Epoch [3/15], Step [1020/1030], Loss: 1.4272\n",
            "Epoch [3/15], Step [1030/1030], Loss: 1.4250\n",
            "Epoch [3/15], Average Training Loss: 1.2559\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7c47945f0900>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7c47945f0900>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7c47945f0900>^Exception ignored in: \n",
            "^<function _MultiProcessingDataLoaderIter.__del__ at 0x7c47945f0900>Traceback (most recent call last):\n",
            "^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            "    ^^^self._shutdown_workers()Traceback (most recent call last):\n",
            "^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            "^    ^    ^self._shutdown_workers()if w.is_alive():^\n",
            "\n",
            "Exception ignored in: Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7c47945f0900>  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            " \n",
            "^     <function _MultiProcessingDataLoaderIter.__del__ at 0x7c47945f0900>Traceback (most recent call last):\n",
            "^if w.is_alive(): ^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            "\n",
            "\n",
            "Exception ignored in:  ^Traceback (most recent call last):\n",
            "      <function _MultiProcessingDataLoaderIter.__del__ at 0x7c47945f0900>^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            " \n",
            "self._shutdown_workers()^      Traceback (most recent call last):\n",
            " ^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            " self._shutdown_workers()^^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            " ^    \n",
            "^    ^ self._shutdown_workers()^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            "if w.is_alive():^ \n",
            "Exception ignored in: ^    \n",
            "^^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            "^if w.is_alive():<function _MultiProcessingDataLoaderIter.__del__ at 0x7c47945f0900> ^^^\n",
            "\n",
            "    ^ ^^Traceback (most recent call last):\n",
            " if w.is_alive(): ^^^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            " \n",
            " ^^^       ^^\n",
            "   self._shutdown_workers()^AssertionError^   ^\n",
            ":   ^^  can only test a child process^\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            "\n",
            " ^ ^      File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^^if w.is_alive():^    ^^^^\n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'^^^\n",
            "^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^^^ ^^     ^ ^ assert self._parent_pid == os.getpid(), 'can only test a child process'^ ^^ ^\n",
            " ^ ^  ^^ ^  ^^ ^ ^^ ^^ ^\n",
            " ^^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            " \n",
            "\n",
            " ^        File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^ assert self._parent_pid == os.getpid(), 'can only test a child process'         ^ \n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'^ assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "  ^^\n",
            "  ^ ^    ^^^    ^^^ ^ ^  ^^^ \n",
            " ^ ^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "  ^  ^^    ^     ^ ^ assert self._parent_pid == os.getpid(), 'can only test a child process'^^^^\n",
            " ^^^^  ^^ ^^  ^^^  ^^^ ^^^^^^^^ ^^^^^ ^^^^^ ^^^^^^ ^^^^^^ ^^^^^ ^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^^AssertionError^^^^^^^: ^\n",
            "^^^^AssertionError^^^can only test a child process: ^^^^can only test a child process^^\n",
            "\n",
            "^^^^^^^^\n",
            "^^AssertionError^^^^Exception ignored in: \n",
            ": ^can only test a child process<function _MultiProcessingDataLoaderIter.__del__ at 0x7c47945f0900>^AssertionError\n",
            "^^\n",
            "^: Traceback (most recent call last):\n",
            "^Exception ignored in: can only test a child process^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            "^<function _MultiProcessingDataLoaderIter.__del__ at 0x7c47945f0900>\n",
            "^\n",
            "    ^^Traceback (most recent call last):\n",
            "^self._shutdown_workers()Exception ignored in: ^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x7c47945f0900>\n",
            "\n",
            "^AssertionError\n",
            ": ^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            "Traceback (most recent call last):\n",
            "    can only test a child process^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            "    self._shutdown_workers()if w.is_alive():Exception ignored in: ^\n",
            "    <function _MultiProcessingDataLoaderIter.__del__ at 0x7c47945f0900>self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            "\n",
            "^\n",
            "\n",
            "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            "     Traceback (most recent call last):\n",
            "Exception ignored in: \n",
            " Exception ignored in:   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            "if w.is_alive():<function _MultiProcessingDataLoaderIter.__del__ at 0x7c47945f0900>     AssertionError<function _MultiProcessingDataLoaderIter.__del__ at 0x7c47945f0900>\n",
            "\n",
            "    :   \n",
            "Traceback (most recent call last):\n",
            " can only test a child processself._shutdown_workers()  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            " Traceback (most recent call last):\n",
            "\n",
            "  \n",
            "        File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            "^if w.is_alive():^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            "     ^self._shutdown_workers()Exception ignored in: if w.is_alive(): \n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x7c47945f0900>\n",
            "    \n",
            "^\n",
            "   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            " ^ ^Traceback (most recent call last):\n",
            "  ^    ^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            "^if w.is_alive():^     \n",
            "self._shutdown_workers()self._shutdown_workers()^^ \n",
            "\n",
            "   ^   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            " ^^        ^     if w.is_alive():^^ ^^  ^\n",
            "if w.is_alive():^^  ^^\n",
            " ^ ^^^^\n",
            "^ ^^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^^  ^^^^  ^    ^^\n",
            "  ^^assert self._parent_pid == os.getpid(), 'can only test a child process'^   File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            " ^\n",
            "^ ^^      ^^^ ^assert self._parent_pid == os.getpid(), 'can only test a child process'^^^^^ \n",
            "^\n",
            "^^^^^  ^^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "\n",
            "^ ^    File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^^    ^  assert self._parent_pid == os.getpid(), 'can only test a child process'    ^^\n",
            "  \n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^   \n",
            "^       ^   ^assert self._parent_pid == os.getpid(), 'can only test a child process'^    ^\n",
            " ^   ^   ^  ^ ^^^ ^ \n",
            " \n",
            " ^^   File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "^^            ^  assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process' ^^ \n",
            "\n",
            " ^^   ^ ^  ^  ^   ^^  ^^  ^ ^^^  ^^ ^ ^^^^  ^^^ ^^^ ^  ^^^^^  ^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "^^^^AssertionError^^^^: \n",
            "^^^^^AssertionError^can only test a child process^^\n",
            "^: ^^^^^^^can only test a child process^^\n",
            "^^^^^^^^^^^^^\n",
            "^^AssertionError^^: ^^^\n",
            "can only test a child process^^^AssertionError^^^\n",
            ": ^\n",
            "^^AssertionError^^: ^^can only test a child process^\n",
            "\n",
            "\n",
            "AssertionErrorAssertionErrorcan only test a child process: can only test a child process\n",
            "\n",
            ": can only test a child processException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7c47945f0900>\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "       ^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "too many indices for tensor of dimension 1",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-540976113.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0mall_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m             \u001b[0mall_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 1"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "from typing import Dict, List, Tuple, Any\n",
        "import numpy as np\n",
        "\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import torch.nn.functional as F\n",
        "\n",
        "num_epochs = 15\n",
        "\n",
        "best_val = 10\n",
        "\n",
        "model = TornadoLikelihood()\n",
        "pos_weight = torch.tensor([(total_number - confirmed_number)/confirmed_number])\n",
        "# De ce label smoothing? Nu e niciodata 100% ca e tornada, SA NU UITI\n",
        "loss_f = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "optimizer = optim.RMSprop(model.parameters(), lr=1e-3)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n",
        "\n",
        "# TensorBoard setup\n",
        "writer = SummaryWriter('/content/drive/MyDrive/proiect_ml/summary')\n",
        "\n",
        "ckpt_path = \"/content/drive/MyDrive/proiect_ml/checkpoints/epoch_002.pth\"\n",
        "ckpt = torch.load(ckpt_path)\n",
        "\n",
        "model.load_state_dict(ckpt[\"model_state\"])\n",
        "optimizer.load_state_dict(ckpt[\"optimizer_state\"])\n",
        "scheduler.load_state_dict(ckpt[\"scheduler_state\"])\n",
        "\n",
        "start_epoch = int(ckpt[\"epoch\"]) + 1   # <- va fi 1\n",
        "best_val = float(ckpt.get(\"val_loss\", 1e9))\n",
        "\n",
        "print(f\"Reluare din {ckpt_path} | start_epoch={start_epoch} | best_val={best_val:.4f}\")\n",
        "\n",
        "# Training loop\n",
        "total_step = len(torch_dl_train)\n",
        "for epoch in range(start_epoch, num_epochs):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    for i, batch in enumerate(torch_dl_train):\n",
        "        y = torch.squeeze(batch.pop('label'))\n",
        "        y = y[:, -1].float()\n",
        "\n",
        "        # Forward pass\n",
        "        logits = model(batch) # [batch,1,T,L,W]\n",
        "        logits = F.max_pool3d(logits, kernel_size=logits.size()[2:]) # [batch,1,1,1,1]\n",
        "        # logits = torch.cat( (-logits,logits),axis=1)  # [batch,2,1,1,1]\n",
        "        logits = torch.squeeze(logits) # [batch,2] for binary classifications\n",
        "        loss = loss_f(logits, y)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        if (i+1) % 10 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{total_step}], Loss: {loss.item():.4f}')\n",
        "\n",
        "        if (i + 1) % 500 == 0:\n",
        "          ckpt_path = f\"/content/drive/MyDrive/proiect_ml/checkpoints/epoch_{epoch+1:03d}.pth\"\n",
        "          torch.save({\n",
        "              \"epoch\": epoch,\n",
        "              \"model_state\": model.state_dict(),\n",
        "              \"optimizer_state\": optimizer.state_dict(),\n",
        "              \"scheduler_state\": scheduler.state_dict(),\n",
        "              \"val_loss\": train_loss,\n",
        "          }, ckpt_path)\n",
        "\n",
        "    # Calculate average training loss for the epoch\n",
        "    avg_train_loss = train_loss / len(torch_dl_train)\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Average Training Loss: {avg_train_loss:.4f}')\n",
        "    writer.add_scalar('training loss', avg_train_loss, epoch)\n",
        "\n",
        "    ckpt_path = f\"/content/drive/MyDrive/proiect_ml/checkpoints/epoch_{epoch+1:03d}.pth\"\n",
        "    torch.save({\n",
        "        \"epoch\": epoch,\n",
        "        \"model_state\": model.state_dict(),\n",
        "        \"optimizer_state\": optimizer.state_dict(),\n",
        "        \"scheduler_state\": scheduler.state_dict(),\n",
        "        \"val_loss\": avg_train_loss,\n",
        "    }, ckpt_path)\n",
        "\n",
        "    # Validation\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        val_loss = 0.0\n",
        "        for i, batch in enumerate(torch_dl_validation):\n",
        "            y = torch.squeeze(batch.pop('label'))\n",
        "            y = y[:, -1].float()\n",
        "\n",
        "            # Forward pass\n",
        "            logits = model(batch) # [batch,1,T,L,W]\n",
        "            logits = F.max_pool3d(logits, kernel_size=logits.size()[2:]) # [batch,1,1,1,1]\n",
        "            # logits = torch.cat( (-logits,logits),axis=1)  # [batch,2,1,1,1]\n",
        "            logits = torch.squeeze(logits) # [batch,2] for binary classification\n",
        "            loss = loss_f(logits, y)\n",
        "\n",
        "            all_probs.append(logits)\n",
        "            all_labels.append(y.reshape(-1))\n",
        "\n",
        "            val_loss += loss.item()\n",
        "\n",
        "        avg_val_loss = val_loss / len(torch_dl_validation)\n",
        "        writer.add_scalar('validation loss', avg_val_loss, epoch)\n",
        "        all_probs = torch.cat(all_probs, dim = 0)\n",
        "        all_labels = torch.cat(all_labels, dim = 0)\n",
        "        apply_metrics(all_probs, all_labels)\n",
        "\n",
        "    if avg_val_loss < best_val:\n",
        "        best_val = avg_val_loss\n",
        "        best_path = \"/content/drive/MyDrive/proiect_ml/checkpoints/best.pth\"\n",
        "        torch.save({\n",
        "            \"epoch\": epoch,\n",
        "            \"model_state\": model.state_dict(),\n",
        "            \"optimizer_state\": optimizer.state_dict(),\n",
        "            \"scheduler_state\": scheduler.state_dict(),\n",
        "            \"val_loss\": avg_val_loss,\n",
        "        }, best_path)\n",
        "        print(f\"[Epoch {epoch+1}] Best model salvat la {best_path} (val_loss={best_val:.4f})\")\n",
        "\n",
        "    # Learning rate scheduling\n",
        "    scheduler.step(avg_val_loss)\n",
        "\n",
        "# Final test\n",
        "\n",
        "all_probs = []\n",
        "all_labels = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  for i, batch in enumerate(torch_dl_test):\n",
        "        y = torch.squeeze(batch.pop('label'))\n",
        "        y = y[:, -1].float()\n",
        "\n",
        "        all_labels.append(y.reshape(-1))\n",
        "\n",
        "        # Forward pass\n",
        "        logits = model(batch) # [batch,1,T,L,W]\n",
        "        logits = F.max_pool3d(logits, kernel_size=logits.size()[2:]) # [batch,1,1,1,1]\n",
        "        # logits = torch.cat( (-logits,logits),axis=1)  # [batch,2,1,1,1]\n",
        "        logits = torch.squeeze(logits) # [batch,2] for binary classification\n",
        "\n",
        "        all_probs.append(logits)\n",
        "\n",
        "all_probs = torch.cat(all_probs, dim = 0)\n",
        "all_labels = torch.cat(all_labels, dim = 0)\n",
        "apply_metrics(all_probs, all_labels)\n",
        "\n",
        "writer.close()\n",
        "\n",
        "# Save the model\n",
        "# torch.save(model.state_dict(), 'tornado_cnn.pth')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1TmDWD6ZoNrM7k3y6VjaTxove4X-58koB",
      "authorship_tag": "ABX9TyM+L0zH/5bDU0U30JGbjXu2",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}