{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saratutuianu/Tornado-detection-using-radar-images/blob/main/tornado_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "uUGxjPZr6nM5",
        "outputId": "43022cb8-e0d0-4d9c-f6cb-61aa5bc12f71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras>=3.0 in /usr/local/lib/python3.12/dist-packages (from -r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 2)) (3.10.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from -r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from -r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 6)) (0.23.0+cu126)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.12/dist-packages (from -r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 13)) (1.8.2)\n",
            "Requirement already satisfied: lightning in /usr/local/lib/python3.12/dist-packages (from -r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 14)) (2.5.5)\n",
            "Requirement already satisfied: numpy~=1.26.0 in /usr/local/lib/python3.12/dist-packages (from -r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 2)) (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from -r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 3)) (3.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from -r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 4)) (2.2.2)\n",
            "Requirement already satisfied: xarray in /usr/local/lib/python3.12/dist-packages (from -r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 5)) (2025.9.0)\n",
            "Requirement already satisfied: netCDF4~=1.6.0 in /usr/local/lib/python3.12/dist-packages (from -r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 6)) (1.6.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from -r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 7)) (4.67.1)\n",
            "Requirement already satisfied: glob2 in /usr/local/lib/python3.12/dist-packages (from -r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 8)) (0.7)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.12/dist-packages (from -r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 9)) (8.4.2)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.12/dist-packages (from -r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (1.1.1)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from -r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 15)) (0.35.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from keras>=3.0->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 2)) (1.4.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.0->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 2)) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.0->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 2)) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from keras>=3.0->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 2)) (3.14.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.0->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 2)) (0.17.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.12/dist-packages (from keras>=3.0->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 2)) (0.5.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from keras>=3.0->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 2)) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (3.4.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 6)) (11.3.0)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 13)) (0.15.2)\n",
            "Requirement already satisfied: PyYAML<8.0,>5.4 in /usr/local/lib/python3.12/dist-packages (from lightning->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 14)) (6.0.2)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.12/dist-packages (from lightning->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 14)) (2.5.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 3)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 3)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 3)) (4.60.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 3)) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 3)) (3.2.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 3)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 4)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 4)) (2025.2)\n",
            "Requirement already satisfied: cftime in /usr/local/lib/python3.12/dist-packages (from netCDF4~=1.6.0->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 6)) (1.6.4.post1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from netCDF4~=1.6.0->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 6)) (2025.8.3)\n",
            "Requirement already satisfied: iniconfig>=1 in /usr/local/lib/python3.12/dist-packages (from pytest->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 9)) (2.1.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.12/dist-packages (from pytest->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 9)) (1.6.0)\n",
            "Requirement already satisfied: pygments>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from pytest->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 9)) (2.19.2)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.12/dist-packages (from jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (6.5.7)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.12/dist-packages (from jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (6.6.3)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.12/dist-packages (from jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (7.16.6)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.12/dist-packages (from jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (6.17.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.12/dist-packages (from jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (7.7.1)\n",
            "Requirement already satisfied: jupyterlab in /usr/local/lib/python3.12/dist-packages (from jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (4.4.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 15)) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 15)) (1.1.10)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<2027.0,>=2022.5.0->lightning->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 14)) (3.12.15)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 3)) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (1.8.15)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (7.4.9)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (26.2.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (6.4.2)\n",
            "Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (5.7.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (3.0.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (3.0.2)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.12/dist-packages (from jupyter-console->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (5.8.1)\n",
            "Requirement already satisfied: prompt-toolkit>=3.0.30 in /usr/local/lib/python3.12/dist-packages (from jupyter-console->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (3.0.52)\n",
            "Requirement already satisfied: async-lru>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (2.0.5)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.28.1)\n",
            "Requirement already satisfied: jupyter-lsp>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (2.3.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (2.14.0)\n",
            "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in /usr/local/lib/python3.12/dist-packages (from jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (2.27.3)\n",
            "Requirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.12/dist-packages (from jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (4.13.5)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (3.1.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.10.2)\n",
            "Requirement already satisfied: nbformat>=5.7 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (5.10.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (1.5.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (25.1.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.22.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (1.3.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 15)) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 15)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 15)) (2.5.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.0->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 2)) (4.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 14)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 14)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 14)) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 14)) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 14)) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 14)) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 14)) (1.20.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (1.4.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.16.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (4.9.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.4)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-console->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (4.4.0)\n",
            "Requirement already satisfied: jupyter-events>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.12.0)\n",
            "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.5.3)\n",
            "Requirement already satisfied: overrides>=5.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (7.7.0)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (1.8.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.12/dist-packages (from argon2-cffi->notebook->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (25.1.0)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.12/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (2.17.0)\n",
            "Requirement already satisfied: json5>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.12.1)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (4.25.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 2)) (0.1.2)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat>=5.7->nbconvert->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (2.21.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.2.13)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.12/dist-packages (from terminado>=0.8.3->notebook->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.7.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->nbconvert->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (2.8)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.25.0->jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (1.3.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.8.5)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.27.1)\n",
            "Requirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (3.3.0)\n",
            "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.1.4)\n",
            "Requirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.1.1)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (2.23)\n",
            "Requirement already satisfied: fqdn in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (1.5.1)\n",
            "Requirement already satisfied: isoduration in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (20.11.0)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (3.0.0)\n",
            "Requirement already satisfied: rfc3987-syntax>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (1.1.0)\n",
            "Requirement already satisfied: uri-template in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (1.3.0)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (24.11.1)\n",
            "Requirement already satisfied: lark>=1.2.2 in /usr/local/lib/python3.12/dist-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (1.2.2)\n",
            "Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (1.3.0)\n",
            "Requirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.12/dist-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (2.9.0.20250822)\n"
          ]
        }
      ],
      "source": [
        "!pip install -r ./drive/MyDrive/proiect_ml/requirements/torch.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0b0tMziB5_b"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "sys.path.append('/content/drive/MyDrive/proiect_ml')\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import importlib, linecache\n",
        "\n",
        "import torch\n",
        "from torch import optim, nn\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms, utils\n",
        "\n",
        "import tornet.data.preprocess as preprocess\n",
        "\n",
        "linecache.checkcache(preprocess.__file__)      # invalideazÄƒ cache-ul de linii\n",
        "preprocess = importlib.reload(preprocess)\n",
        "\n",
        "from tornet.data.loader import read_file, TornadoDataLoader\n",
        "from tornet.data.preprocess import add_coordinates, permute_dims, remove_tilt_dim, get_shape\n",
        "from tornet.data.constants import ALL_VARIABLES\n",
        "\n",
        "data_root=r'./drive/MyDrive/proiect_ml/tornet_dataset'\n",
        "\n",
        "year = 2019\n",
        "\n",
        "catalog_path = os.path.join(data_root,'catalog.csv')\n",
        "\n",
        "catalog = pd.read_csv(catalog_path,parse_dates=['start_time','end_time'])\n",
        "\n",
        "catalog['J'] = catalog['start_time'].dt.dayofyear\n",
        "catalog['r'] = catalog['J'] % 20\n",
        "catalog = catalog[catalog.start_time.dt.year == 2019]\n",
        "\n",
        "catalog_test = catalog[catalog['type'] == 'test']\n",
        "catalog_test = catalog_test.sample(frac=1,random_state=1234) # shuffles list\n",
        "\n",
        "catalog = catalog[catalog['type']=='train']\n",
        "\n",
        "catalog_train = catalog[catalog['r'] <= 13]\n",
        "catalog_train = catalog_train.sample(frac=1,random_state=1234) # shuffles list\n",
        "\n",
        "catalog_validation = catalog[(catalog['r'] > 13) & (catalog['r'] < 17)]\n",
        "catalog_validation = catalog_validation.sample(frac=1,random_state=1234) # shuffles list\n",
        "\n",
        "confirmed_number = len(catalog_train[catalog_train['category'] == 'TOR'])\n",
        "total_number = len(catalog_train)\n",
        "\n",
        "class TornadoDataset(TornadoDataLoader,Dataset):\n",
        "    pass\n",
        "\n",
        "transform = transforms.Compose([\n",
        "            lambda d: remove_tilt_dim(d)\n",
        "            ])\n",
        "\n",
        "file_list_train = [os.path.join(data_root,f) for f in catalog_train.filename]\n",
        "file_list_validation = [os.path.join(data_root,f) for f in catalog_validation.filename]\n",
        "file_list_test = [os.path.join(data_root,f) for f in catalog_test.filename]\n",
        "\n",
        "torch_ds_train = TornadoDataset(file_list_train,\n",
        "                          variables=ALL_VARIABLES,\n",
        "                          n_frames=4,\n",
        "                          tilt_last=False, # so ordering of dims is [time,tilt,az,range]\n",
        "                          transform=transform)\n",
        "\n",
        "torch_ds_validation = TornadoDataset(file_list_validation,\n",
        "                          variables=ALL_VARIABLES,\n",
        "                          n_frames=4,\n",
        "                          tilt_last=False, # so ordering of dims is [time,tilt,az,range]\n",
        "                          transform=transform)\n",
        "\n",
        "torch_ds_test = TornadoDataset(file_list_test,\n",
        "                          variables=ALL_VARIABLES,\n",
        "                          n_frames=4,\n",
        "                          tilt_last=False, # so ordering of dims is [time,tilt,az,range]\n",
        "                          transform=transform)\n",
        "\n",
        "\n",
        "batch_size=16\n",
        "\n",
        "torch_dl_train = torch.utils.data.DataLoader( torch_ds_train,\n",
        "                                        batch_size=batch_size,\n",
        "                                        num_workers=8 )\n",
        "\n",
        "torch_dl_validation = torch.utils.data.DataLoader( torch_ds_validation,\n",
        "                                        batch_size=batch_size,\n",
        "                                        num_workers=8 )\n",
        "\n",
        "torch_dl_test = torch.utils.data.DataLoader( torch_ds_test,\n",
        "                                        batch_size=batch_size,\n",
        "                                        num_workers=8 )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTh_wMXVO3ld"
      },
      "outputs": [],
      "source": [
        "from tornet.models.torch.cnn_baseline import NormalizeVariable\n",
        "from tornet.data.constants import CHANNEL_MIN_MAX\n",
        "\n",
        "def conv3d_bn_block(in_channels, out_channels, kernel_size=3, stride=1, padding='same'):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv3d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
        "        nn.BatchNorm3d(out_channels),\n",
        "        nn.ReLU(inplace=True)\n",
        "    )\n",
        "\n",
        "def conv3d_transpose_bn_block(in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
        "    return nn.Sequential(\n",
        "        nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
        "    )\n",
        "\n",
        "class TornadoLikelihood(nn.Module):\n",
        "    def __init__(self,radar_variables=ALL_VARIABLES):\n",
        "      super(TornadoLikelihood, self).__init__()\n",
        "      self.radar_variables=radar_variables\n",
        "\n",
        "      # Partea de encoder\n",
        "      self.conv_layer_encoder1 = conv3d_bn_block(in_channels=len(radar_variables), out_channels=16)\n",
        "      self.conv_layer_encoder2 = conv3d_bn_block(in_channels=16, out_channels=16)\n",
        "\n",
        "      self.max_pool_encoder1 = nn.MaxPool3d(kernel_size=(1,2,2), stride=(1,2,2))\n",
        "\n",
        "      self.conv_layer_encoder3 = conv3d_bn_block(in_channels=16, out_channels=32)\n",
        "      self.conv_layer_encoder4 = conv3d_bn_block(in_channels=32, out_channels=32)\n",
        "\n",
        "      self.max_pool_encoder2 = nn.MaxPool3d(kernel_size=(1,2,2), stride=(1,2,2))\n",
        "\n",
        "      self.conv_layer_encoder5 = conv3d_bn_block(in_channels=32, out_channels=64)\n",
        "      self.conv_layer_encoder6 = conv3d_bn_block(in_channels=64, out_channels=64)\n",
        "\n",
        "      self.max_pool_encoder3 = nn.MaxPool3d(kernel_size=2, stride=2)\n",
        "\n",
        "      self.conv_layer_encoder7 = conv3d_bn_block(in_channels=64, out_channels=128)\n",
        "      self.conv_layer_encoder8 = conv3d_bn_block(in_channels=128, out_channels=128)\n",
        "\n",
        "      self.max_pool_encoder4 = nn.MaxPool3d(kernel_size=2, stride=2)\n",
        "\n",
        "      # Partea de decoder\n",
        "      self.conv_layer_decoder1 = conv3d_bn_block(in_channels=128, out_channels=128)\n",
        "      self.conv_layer_decoder2 = conv3d_bn_block(in_channels=128, out_channels=128)\n",
        "\n",
        "      self.upsample_decoder1 = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)\n",
        "\n",
        "      self.conv_layer_decoder3 = conv3d_bn_block(in_channels=128, out_channels=64)\n",
        "      self.conv_layer_decoder4 = conv3d_bn_block(in_channels=64, out_channels=64)\n",
        "\n",
        "      self.upsample_decoder2 = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)\n",
        "\n",
        "      self.conv_layer_decoder5 = conv3d_bn_block(in_channels=64, out_channels=32)\n",
        "      self.conv_layer_decoder6 = conv3d_bn_block(in_channels=32, out_channels=32)\n",
        "\n",
        "      self.upsample_decoder3 = nn.Upsample(scale_factor=(1,2,2), mode='trilinear', align_corners=True)\n",
        "\n",
        "      self.conv_layer_decoder7 = conv3d_bn_block(in_channels=32, out_channels=16)\n",
        "      self.conv_layer_decoder8 = conv3d_bn_block(in_channels=16, out_channels=16)\n",
        "\n",
        "      self.upsample_decoder4 = nn.Upsample(scale_factor=(1,2,2), mode='trilinear', align_corners=True)\n",
        "\n",
        "      self.conv_layer_final = conv3d_transpose_bn_block(in_channels=16, out_channels=1)\n",
        "\n",
        "    def _normalize_inputs(self,data):\n",
        "        normed_data = {}\n",
        "        for v in self.radar_variables:\n",
        "            min_max = np.array(CHANNEL_MIN_MAX[v]) # [2,]\n",
        "            scale = 1/(min_max[1]-min_max[0])\n",
        "            offset = min_max[0]\n",
        "            normed_data[v] = (data[v] - offset) * scale\n",
        "\n",
        "        return normed_data\n",
        "\n",
        "    def forward(self,x):\n",
        "      \"\"\"\n",
        "      Assumes x contains radar varialbes on [batch,tilt,az,rng]\n",
        "      \"\"\"\n",
        "      # extract radar inputs\n",
        "      x = {v:x[v] for v in self.radar_variables} # each [batch,time,Az,Rng]\n",
        "      # normalize\n",
        "      x = self._normalize_inputs(x) # each [batch,time,Az,Rng]\n",
        "      # concatenate along channel (time) dim\n",
        "      x = torch.stack([x[v] for v in self.radar_variables], dim=1)\n",
        "\n",
        "      x = torch.where(torch.isnan(x),-3,x)\n",
        "\n",
        "      x = self.conv_layer_encoder1(x)\n",
        "      x = self.conv_layer_encoder2(x)\n",
        "      x = self.max_pool_encoder1(x)\n",
        "\n",
        "      x = self.conv_layer_encoder3(x)\n",
        "      x = self.conv_layer_encoder4(x)\n",
        "      x = self.max_pool_encoder2(x)\n",
        "\n",
        "      x = self.conv_layer_encoder5(x)\n",
        "      x = self.conv_layer_encoder6(x)\n",
        "      x = self.max_pool_encoder3(x)\n",
        "\n",
        "      x = self.conv_layer_encoder7(x)\n",
        "      x = self.conv_layer_encoder8(x)\n",
        "      x = self.max_pool_encoder4(x)\n",
        "\n",
        "      x = self.conv_layer_decoder1(x)\n",
        "      x = self.conv_layer_decoder2(x)\n",
        "      x = self.upsample_decoder1(x)\n",
        "\n",
        "      x = self.conv_layer_decoder3(x)\n",
        "      x = self.conv_layer_decoder4(x)\n",
        "      x = self.upsample_decoder2(x)\n",
        "\n",
        "      x = self.conv_layer_decoder5(x)\n",
        "      x = self.conv_layer_decoder6(x)\n",
        "      x = self.upsample_decoder3(x)\n",
        "\n",
        "      x = self.conv_layer_decoder7(x)\n",
        "      x = self.conv_layer_decoder8(x)\n",
        "      x = self.upsample_decoder4(x)\n",
        "\n",
        "      x = self.conv_layer_final(x)\n",
        "\n",
        "      return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KwrKOwlw8Urj"
      },
      "outputs": [],
      "source": [
        "import torchmetrics\n",
        "from torchmetrics.functional.classification import binary_auroc, binary_average_precision\n",
        "\n",
        "def accuracy(logits, y, tres):\n",
        "  correct = 0\n",
        "  for i in range(len(logits)):\n",
        "    if logits[i] >= tres and y[i] == 1:\n",
        "      correct += 1\n",
        "    elif logits[i] < tres and y[i] == 0:\n",
        "      correct += 1\n",
        "\n",
        "  return correct / float(len(y)) * 100.0\n",
        "\n",
        "def recall(logits, y, tres):\n",
        "  correct = 0\n",
        "  false_negatives = 0\n",
        "  for i in range(len(logits)):\n",
        "    if logits[i] >= tres and y[i] == 1:\n",
        "      correct += 1\n",
        "    elif logits[i] < tres and y[i] == 1:\n",
        "      false_negatives += 1\n",
        "\n",
        "  return 0.0 if correct + false_negatives == 0 else correct / (correct + false_negatives) * 100.0\n",
        "\n",
        "def precision(logits, y, tres):\n",
        "  correct = 0\n",
        "  false_positives = 0\n",
        "  for i in range(len(logits)):\n",
        "    if logits[i] >= tres and y[i] == 1:\n",
        "      correct += 1\n",
        "    elif logits[i] >= tres and y[i] == 0:\n",
        "      false_positives += 1\n",
        "\n",
        "  return 0.0 if correct + false_positives == 0 else correct / (correct + false_positives) * 100.0\n",
        "\n",
        "def f1_score(logits, y, tres):\n",
        "  p = precision(logits, y, tres)\n",
        "  r = recall(logits, y, tres)\n",
        "  return 0.0 if p + r == 0 else 2 * (p * r) / (p + r)\n",
        "\n",
        "def apply_metrics(logits, y, avg_train_loss, avg_val_loss, best_treshold):\n",
        "  acc = accuracy(logits, y, best_treshold)\n",
        "  rec = recall(logits, y, best_treshold)\n",
        "  prec = precision(logits, y, best_treshold)\n",
        "  f1 = f1_score(logits, y, best_treshold)\n",
        "  auroc = binary_auroc(logits, y)\n",
        "  auprc = binary_average_precision(logits, y)\n",
        "\n",
        "  print(f\"Accuracy: , {acc:.4f}\")\n",
        "  print(f\"Recall: , {rec:.4f}\")\n",
        "  print(f\"Precision: , {prec:.4f}\")\n",
        "  print(f\"F1 Score: , {f1:.4f}\")\n",
        "  print(f\"AUROC:  {auroc.item():.4f}\")\n",
        "  print(f\"AUPRC:  {auprc.item():.4f}\")\n",
        "\n",
        "  return {\n",
        "      'accuracy': acc,\n",
        "      'recall': rec,\n",
        "      'precision': prec,\n",
        "      'f1_score': f1,\n",
        "      'auroc': auroc.item(),\n",
        "      'auprc': auprc.item(),\n",
        "      'avg_train_loss': avg_train_loss,\n",
        "      'avg_val_loss': avg_val_loss,\n",
        "      'threshold': best_treshold\n",
        "  }\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# recall mai important! -> e mai important sa flaguiasca toate tornadele, decat sa nu emita avertizari negative\n",
        "!pip install plotnine\n",
        "import plotnine\n",
        "from plotnine import *\n",
        "from IPython.display import display\n",
        "\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "def find_best_tres(logits, y, beta):\n",
        "  precision, recall, thresholds = precision_recall_curve(y, logits)\n",
        "\n",
        "  # Plot the precision-recall curve\n",
        "  df_recall_precision = pd.DataFrame({'Precision':precision[:-1],\n",
        "                                      'Recall':recall[:-1],\n",
        "                                      'Threshold':thresholds})\n",
        "  df_recall_precision.head()\n",
        "\n",
        "  plotnine.options.figure_size = (8, 4.8)\n",
        "\n",
        "  # Creat a data viz\n",
        "  plot1 = (\n",
        "      ggplot(data = df_recall_precision) +\n",
        "      geom_point(aes(x='Recall', y='Precision'), size=0.4) +\n",
        "      geom_line(aes(x='Recall', y='Precision')) +\n",
        "      labs(title='Recall Precision Curve') +\n",
        "      xlab('Recall') +\n",
        "      ylab('Precision') +\n",
        "      theme_minimal()\n",
        "  )\n",
        "  display(plot1)\n",
        "\n",
        "  precision = precision[:-1]\n",
        "  recall = recall[:-1]\n",
        "\n",
        "  den = (beta**2)*precision + recall\n",
        "  fbeta_score = np.where(den > 0, (1 + beta**2) * precision * recall / den, -np.inf)\n",
        "\n",
        "  # Find the optimal threshold\n",
        "  index = np.argmax(fbeta_score)\n",
        "  thresholdOpt = round(thresholds[index], ndigits = 4)\n",
        "  fscoreOpt = round(fbeta_score[index], ndigits = 4)\n",
        "  recallOpt = round(recall[index], ndigits = 4)\n",
        "  precisionOpt = round(precision[index], ndigits = 4)\n",
        "  print('Best Threshold: {} with F-Score: {}'.format(thresholdOpt, fscoreOpt))\n",
        "  print('Recall: {}, Precision: {}'.format(recallOpt, precisionOpt))\n",
        "\n",
        "  plotnine.options.figure_size = (8, 4.8)\n",
        "\n",
        "  # Create a data viz\n",
        "  plot2 = (\n",
        "    ggplot(data = df_recall_precision)+\n",
        "    geom_point(aes(x = 'Recall',\n",
        "                    y = 'Precision'),\n",
        "                size = 0.4)+\n",
        "    # Best threshold\n",
        "    geom_point(aes(x = recallOpt,\n",
        "                    y = precisionOpt),\n",
        "                color = '#981220',\n",
        "                size = 4)+\n",
        "    geom_line(aes(x = 'Recall',\n",
        "                  y = 'Precision'))+\n",
        "    # Annotate the text\n",
        "    geom_text(aes(x = recallOpt,\n",
        "                  y = precisionOpt),\n",
        "              label = 'Optimal threshold \\n for class: {}'.format(thresholdOpt),\n",
        "              nudge_x = 0.18,\n",
        "              nudge_y = 0,\n",
        "              size = 10,\n",
        "              fontstyle = 'italic')+\n",
        "    labs(title = 'Recall Precision Curve')+\n",
        "    xlab('Recall')+\n",
        "    ylab('Precision')+\n",
        "    theme_minimal()\n",
        "  )\n",
        "\n",
        "  display(plot2)\n",
        "\n",
        "  return thresholdOpt\n"
      ],
      "metadata": {
        "id": "HQrz833PWpQa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adf75880-2601-4e0f-a4be-7d26ff091738"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: plotnine in /usr/local/lib/python3.12/dist-packages (0.14.5)\n",
            "Requirement already satisfied: matplotlib>=3.8.0 in /usr/local/lib/python3.12/dist-packages (from plotnine) (3.10.0)\n",
            "Requirement already satisfied: pandas>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from plotnine) (2.2.2)\n",
            "Requirement already satisfied: mizani~=0.13.0 in /usr/local/lib/python3.12/dist-packages (from plotnine) (0.13.5)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.12/dist-packages (from plotnine) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from plotnine) (1.16.2)\n",
            "Requirement already satisfied: statsmodels>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from plotnine) (0.14.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8.0->plotnine) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8.0->plotnine) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8.0->plotnine) (4.60.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8.0->plotnine) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8.0->plotnine) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8.0->plotnine) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8.0->plotnine) (3.2.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8.0->plotnine) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.0->plotnine) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.0->plotnine) (2025.2)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.12/dist-packages (from statsmodels>=0.14.0->plotnine) (1.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.8.0->plotnine) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from time import time\n",
        "import logging\n",
        "\n",
        "training_logs = []\n",
        "class TrainingLogger:\n",
        "    def __init__(self):\n",
        "        logging.basicConfig(level=logging.INFO, format='%(message)s', filename='/content/drive/MyDrive/proiect_ml/training.log', filemode='a')\n",
        "\n",
        "    def on_epoch_begin(self, epoch):\n",
        "        self.epoch_start_time = time()\n",
        "        logging.info(f\"Epoch {epoch + 1} starting.\")\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        elapsed_time = time() - self.epoch_start_time\n",
        "        logging.info(f\"Epoch {epoch + 1} finished in {elapsed_time:.2f} seconds.\")\n",
        "        logs['epoch_time'] = elapsed_time  # Add epoch time to logs\n",
        "        training_logs.append(logs)  # Collect training logs\n",
        "        logging.info(f\"Epoch {epoch + 1}: Val loss = {logs['avg_val_loss']:.4f}, Accuracy = {logs['accuracy']:.4f}, Recall = {logs['recall']:.4f}, Precision = {logs['precision']:.4f}, F1 = {logs['f1_score']:.4f}, AUROC = {logs['auroc']:.4f}, AUPRC = {logs['auprc']:.4f}\")\n"
      ],
      "metadata": {
        "id": "1ebH4pzJ9CjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JIJRviy1KmYa"
      },
      "outputs": [],
      "source": [
        "from torch.optim import Optimizer\n",
        "\n",
        "class RMSpropFromScratch(Optimizer):\n",
        "    def __init__(self, params, lr=1e-3, alpha=0.99, eps=1e-8,\n",
        "                 weight_decay=0.0, momentum=0.0, centered=False):\n",
        "\n",
        "        defaults = dict(lr=lr, alpha=alpha, eps=eps,\n",
        "                        weight_decay=weight_decay, momentum=momentum,\n",
        "                        centered=centered)\n",
        "        super().__init__(params, defaults)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def step(self, closure=None):\n",
        "        loss = None\n",
        "\n",
        "        if closure is not None:\n",
        "            with torch.enable_grad():\n",
        "                loss = closure()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            lr = group['lr']\n",
        "            alpha = group['alpha']\n",
        "            eps = group['eps']\n",
        "            wd = group['weight_decay']\n",
        "\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "\n",
        "                grad = p.grad\n",
        "\n",
        "                # weight decay: g <- g + wd * w\n",
        "                if wd != 0.0:\n",
        "                    grad = grad.add(p, alpha=wd)\n",
        "\n",
        "                state = self.state[p]\n",
        "                # init state\n",
        "                if len(state) == 0:\n",
        "                    state[\"square_avg\"] = torch.zeros_like(p, memory_format=torch.preserve_format)  # E[g^2]\n",
        "\n",
        "                    if group[\"momentum\"] > 0:\n",
        "                      state[\"momentum_buffer\"] = torch.zeros_like(p, memory_format=torch.preserve_format)\n",
        "\n",
        "                    if group[\"centered\"]:\n",
        "                      state[\"grad_avg\"] = torch.zeros_like(p, memory_format=torch.preserve_format)  # E[g]\n",
        "\n",
        "                square_avg = state['square_avg']\n",
        "                square_avg.mul_(alpha).addcmul_(grad, grad, value=1 - alpha)\n",
        "\n",
        "                if group['centered']:\n",
        "                    grad_avg = state['grad_avg']\n",
        "                    grad_avg.mul_(alpha).add_(grad, alpha=1 - alpha)\n",
        "                    # var â‰ˆ E[g^2] - (E[g])^2\n",
        "                    avg = square_avg.addcmul(grad_avg, grad_avg, value=-1).sqrt_()\n",
        "                else:\n",
        "                    avg = square_avg.sqrt()\n",
        "\n",
        "                avg = avg.add_(eps)\n",
        "\n",
        "                if group['momentum'] > 0.0:\n",
        "                    buf = state['momentum_buffer']\n",
        "                    buf.mul_(['momentum']).addcdiv_(grad, avg)\n",
        "                    p.add_(buf, alpha=-lr)\n",
        "                else:\n",
        "                    p.addcdiv_(grad, avg, value=-lr)\n",
        "\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import logging\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from time import time\n",
        "\n",
        "from typing import Dict, List, Tuple, Any\n",
        "import numpy as np\n",
        "\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import torch.nn.functional as F\n",
        "\n",
        "num_epochs = 15\n",
        "\n",
        "best_val = 10\n",
        "\n",
        "model = TornadoLikelihood()\n",
        "\n",
        "pos_weight = torch.tensor([(total_number - confirmed_number)/confirmed_number])  # weight asociat cu clasa pozitiva\n",
        "loss_f = nn.BCEWithLogitsLoss(pos_weight=pos_weight)  # daca w_p > 1 => favorizeaza recall, invers => precision\n",
        "\n",
        "optimizer = RMSpropFromScratch(model.parameters(), lr=1e-3)\n",
        "\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n",
        "\n",
        "# TensorBoard setup\n",
        "writer = SummaryWriter('/content/drive/MyDrive/proiect_ml/summary')\n",
        "\n",
        "ckpt_path = \"/content/drive/MyDrive/proiect_ml/checkpoints/best.pth\"\n",
        "ckpt = torch.load(ckpt_path)\n",
        "\n",
        "model.load_state_dict(ckpt[\"model_state\"])\n",
        "optimizer.load_state_dict(ckpt[\"optimizer_state\"])\n",
        "scheduler.load_state_dict(ckpt[\"scheduler_state\"])\n",
        "\n",
        "start_epoch = int(ckpt[\"epoch\"]) + 1   # <- va fi 1\n",
        "best_val = float(ckpt.get(\"val_loss\", 1e9))\n",
        "\n",
        "print(f\"Reluare din {ckpt_path} | start_epoch={start_epoch} | best_val={best_val:.4f}\")\n",
        "\n",
        "best_treshold = 0.6\n",
        "\n",
        "avg_val_loss = best_val\n",
        "avg_train_loss = 0.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1D03Yu7yulR8",
        "outputId": "d67392ca-3fb8-48d1-8d27-cfa961afd693"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reluare din /content/drive/MyDrive/proiect_ml/checkpoints/best.pth | start_epoch=14 | best_val=0.9965\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "-Ii192qVskex",
        "outputId": "25a21370-1d81-46d2-dee1-4cb885c784ae"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorboard/compat/__init__.py\u001b[0m in \u001b[0;36mtf\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnotf\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'notf' from 'tensorboard.compat' (/usr/local/lib/python3.12/dist-packages/tensorboard/compat/__init__.py)",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3825974809.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorboard\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/tensorboard/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFileWriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_writer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRecordWriter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/tensorboard/writer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_convert_np\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_np\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_embedding\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_embedding_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmake_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmake_sprite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmake_tsv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_pbtxt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_onnx_graph\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_onnx_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_pytorch_graph\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/tensorboard/_embedding.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0m_HAS_GFILE_JOIN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"join\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorboard/lazy.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr_name)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mclass\u001b[0m \u001b[0mLazyModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModuleType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0m__dir__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorboard/lazy.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(arg)\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnothing\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mnothing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m                     \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorboard/lazy.py\u001b[0m in \u001b[0;36mload_once\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mload_once\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloading\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                 \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mload_once\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloading\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorboard/compat/__init__.py\u001b[0m in \u001b[0;36mtf\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0m_tf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__internal__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__operators__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/_api/v2/__internal__/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_ctx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontrol_status_ctx\u001b[0m \u001b[0;31m# line: 34\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf_convert\u001b[0m \u001b[0;31m# line: 493\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/autograph/core/ag_ctx.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mag_logging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_export\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf_export\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/autograph/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\"\"\"Utility module that contains APIs usable in the generated code.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext_managers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontrol_dependency_on_returns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0malias_tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_list\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdynamic_list_append\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/autograph/utils/context_managers.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_array_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/ops/tensor_array_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtype_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtype_spec_registry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray_ops_stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontrol_flow_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mtf_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"size\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 802\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_dispatch_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    803\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m   \u001b[0;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36madd_dispatch_support\u001b[0;34m(target, iterable_parameters)\u001b[0m\n\u001b[1;32m   1279\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1281\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mdecorator\u001b[0;34m(dispatch_target)\u001b[0m\n\u001b[1;32m   1244\u001b[0m       ]\n\u001b[1;32m   1245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1246\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mtraceback_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mop_dispatch_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m       \u001b[0;34m\"\"\"Call `dispatch_target`, performing dispatch when appropriate.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36mfilter_traceback\u001b[0;34m(fn)\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_decorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/util/tf_decorator.py\u001b[0m in \u001b[0;36mmake_decorator\u001b[0;34m(target, decorator_func, decorator_name, decorator_doc, decorator_argspec)\u001b[0m\n\u001b[1;32m    134\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdecorator_name\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0mdecorator_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrentframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_back\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_code\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mco_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m   decorator = TFDecorator(decorator_name, target, decorator_doc,\n\u001b[0m\u001b[1;32m    137\u001b[0m                           decorator_argspec)\n\u001b[1;32m    138\u001b[0m   \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecorator_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_tf_decorator'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/util/tf_decorator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, decorator_name, target, decorator_doc, decorator_argspec)\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__signature__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0;31m# Certain callables such as builtins can not be inspected for signature.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/inspect.py\u001b[0m in \u001b[0;36msignature\u001b[0;34m(obj, follow_wrapped, globals, locals, eval_str)\u001b[0m\n\u001b[1;32m   3346\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_wrapped\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_str\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3347\u001b[0m     \u001b[0;34m\"\"\"Get a signature object for the passed callable.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3348\u001b[0;31m     return Signature.from_callable(obj, follow_wrapped=follow_wrapped,\n\u001b[0m\u001b[1;32m   3349\u001b[0m                                    globals=globals, locals=locals, eval_str=eval_str)\n\u001b[1;32m   3350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/inspect.py\u001b[0m in \u001b[0;36mfrom_callable\u001b[0;34m(cls, obj, follow_wrapped, globals, locals, eval_str)\u001b[0m\n\u001b[1;32m   3083\u001b[0m                       follow_wrapped=True, globals=None, locals=None, eval_str=False):\n\u001b[1;32m   3084\u001b[0m         \u001b[0;34m\"\"\"Constructs Signature for the given callable object.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3085\u001b[0;31m         return _signature_from_callable(obj, sigcls=cls,\n\u001b[0m\u001b[1;32m   3086\u001b[0m                                         \u001b[0mfollow_wrapper_chains\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_wrapped\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3087\u001b[0m                                         globals=globals, locals=locals, eval_str=eval_str)\n",
            "\u001b[0;32m/usr/lib/python3.12/inspect.py\u001b[0m in \u001b[0;36m_signature_from_callable\u001b[0;34m(obj, follow_wrapper_chains, skip_bound_arg, globals, locals, eval_str, sigcls)\u001b[0m\n\u001b[1;32m   2547\u001b[0m         \u001b[0msig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__signature__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2548\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2549\u001b[0;31m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2550\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2551\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msig\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "patience = 5\n",
        "patience_counter = 0\n",
        "\n",
        "callback = TrainingLogger()\n",
        "\n",
        "# Training loop\n",
        "total_step = len(torch_dl_train)\n",
        "\n",
        "eps = 0.05\n",
        "\n",
        "for epoch in range(start_epoch, num_epochs):\n",
        "    callback.on_epoch_begin(epoch)\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "\n",
        "    for i, batch in enumerate(torch_dl_train):\n",
        "        y = torch.squeeze(batch.pop('label'))\n",
        "        y_float = y[:, -1].float()\n",
        "\n",
        "        # De ce label smoothing? Nu e niciodata 100% ca e tornada\n",
        "        y_smooth = y_float * (1 - 2*eps) + eps\n",
        "\n",
        "        # Forward pass\n",
        "        logits = model(batch) # [batch,1,T,L,W]\n",
        "        logits = F.max_pool3d(logits, kernel_size=logits.size()[2:]) # [batch,1,1,1,1]\n",
        "        logits = torch.squeeze(logits) # [batch,1] for binary classifications\n",
        "        loss = loss_f(logits, y_smooth)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        if (i+1) % 10 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{total_step}], Loss: {loss.item():.4f}')\n",
        "\n",
        "    # Calculate average training loss for the epoch\n",
        "    avg_train_loss = train_loss / len(torch_dl_train)\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Average Training Loss: {avg_train_loss:.4f}')\n",
        "    writer.add_scalar('training loss', avg_train_loss, epoch)\n",
        "\n",
        "    ckpt_path = f\"/content/drive/MyDrive/proiect_ml/checkpoints/epoch_{epoch+1:03d}.pth\"\n",
        "    torch.save({\n",
        "        \"epoch\": epoch,\n",
        "        \"model_state\": model.state_dict(),\n",
        "        \"optimizer_state\": optimizer.state_dict(),\n",
        "        \"scheduler_state\": scheduler.state_dict(),\n",
        "        \"val_loss\": avg_train_loss,\n",
        "    }, ckpt_path)\n",
        "\n",
        "    # Validation\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        val_loss = 0.0\n",
        "        for i, batch in enumerate(torch_dl_validation):\n",
        "            y = torch.squeeze(batch.pop('label'))\n",
        "            y_float = y[:, -1].float()\n",
        "            y_int = y[:, -1].long()\n",
        "\n",
        "            # Forward pass\n",
        "            logits = model(batch) # [batch,1,T,L,W]\n",
        "            logits = F.max_pool3d(logits, kernel_size=logits.size()[2:]) # [batch,1,1,1,1]\n",
        "            logits = torch.squeeze(logits) # [batch,1] for binary classifications\n",
        "            loss = loss_f(logits, y_float)\n",
        "\n",
        "            all_probs.append(torch.sigmoid(logits))\n",
        "            all_labels.append(y_int)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "\n",
        "        avg_val_loss = val_loss / len(torch_dl_validation)\n",
        "        writer.add_scalar('validation loss', avg_val_loss, epoch)\n",
        "        all_probs = torch.cat(all_probs, dim = 0)\n",
        "        all_labels = torch.cat(all_labels, dim = 0)\n",
        "\n",
        "    if avg_val_loss < best_val:\n",
        "        best_val = avg_val_loss\n",
        "        best_path = \"/content/drive/MyDrive/proiect_ml/checkpoints/best.pth\"\n",
        "        torch.save({\n",
        "            \"epoch\": epoch,\n",
        "            \"model_state\": model.state_dict(),\n",
        "            \"optimizer_state\": optimizer.state_dict(),\n",
        "            \"scheduler_state\": scheduler.state_dict(),\n",
        "            \"val_loss\": avg_val_loss,\n",
        "        }, best_path)\n",
        "        print(f\"[Epoch {epoch+1}] Best model salvat la {best_path} (val_loss={best_val:.4f})\")\n",
        "\n",
        "        patience_counter = 0\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Early stopping triggered at epoch {epoch+1}.\")\n",
        "            break\n",
        "\n",
        "    # Learning rate scheduling\n",
        "    scheduler.step(avg_val_loss)\n",
        "\n",
        "    logs = apply_metrics(all_probs, all_labels, avg_train_loss, avg_val_loss, best_treshold)\n",
        "\n",
        "    best_treshold = find_best_tres(all_probs, all_labels, 2)\n",
        "\n",
        "    callback.on_epoch_end(epoch, logs)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Final test\n",
        "\n",
        "all_probs = []\n",
        "all_labels = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  for i, batch in enumerate(torch_dl_test):\n",
        "        y = torch.squeeze(batch.pop('label'))\n",
        "        y_float = y[:, -1].float()\n",
        "        y_int = y[:, -1].long()\n",
        "\n",
        "        # Forward pass\n",
        "        logits = model(batch) # [batch,1,T,L,W]\n",
        "        logits = F.max_pool3d(logits, kernel_size=logits.size()[2:]) # [batch,1,1,1,1]\n",
        "        logits = torch.squeeze(logits) # [batch,1] for binary classifications\n",
        "\n",
        "        all_probs.append(torch.sigmoid(logits))\n",
        "        all_labels.append(y_int)\n",
        "\n",
        "all_probs = torch.cat(all_probs, dim = 0)\n",
        "all_labels = torch.cat(all_labels, dim = 0)\n",
        "logs = apply_metrics(all_probs, all_labels, avg_train_loss, avg_val_loss, best_treshold)\n",
        "\n",
        "callback.on_epoch_end(epoch, logs)\n",
        "\n",
        "writer.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "Pl_hxRZkCtz8",
        "outputId": "d5640414-4787-457b-d7be-f7a1599bdf8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: , 73.2076\n",
            "Recall: , 62.5000\n",
            "Precision: , 11.4841\n",
            "F1 Score: , 19.4030\n",
            "AUROC:  0.7084\n",
            "AUPRC:  0.1349\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'callback' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3694780238.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_train_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_val_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_treshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'callback' is not defined"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1TmDWD6ZoNrM7k3y6VjaTxove4X-58koB",
      "authorship_tag": "ABX9TyPDXEDUY7ph8utc5dlzifUV",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}