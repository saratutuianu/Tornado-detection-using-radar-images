{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saratutuianu/Tornado-detection-using-radar-images/blob/main/tornado_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "uUGxjPZr6nM5",
        "outputId": "8c72419f-6eab-4801-d6d4-d88f907770c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras>=3.0 in /usr/local/lib/python3.12/dist-packages (from -r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 2)) (3.10.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from -r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from -r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 6)) (0.24.0+cu126)\n",
            "Collecting torchmetrics (from -r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 13))\n",
            "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting lightning (from -r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 14))\n",
            "  Downloading lightning-2.6.1-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy~=1.26.0 (from -r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 2))\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from -r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 3)) (3.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from -r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 4)) (2.2.2)\n",
            "Requirement already satisfied: xarray in /usr/local/lib/python3.12/dist-packages (from -r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 5)) (2025.12.0)\n",
            "Collecting netCDF4~=1.6.0 (from -r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 6))\n",
            "  Downloading netCDF4-1.6.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from -r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 7)) (4.67.2)\n",
            "Requirement already satisfied: glob2 in /usr/local/lib/python3.12/dist-packages (from -r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 8)) (0.7)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.12/dist-packages (from -r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 9)) (8.4.2)\n",
            "Collecting jupyter (from -r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12))\n",
            "  Downloading jupyter-1.1.1-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from -r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 15)) (1.3.7)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from keras>=3.0->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 2)) (1.4.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.0->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 2)) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.0->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 2)) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from keras>=3.0->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 2)) (3.15.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.0->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 2)) (0.18.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.12/dist-packages (from keras>=3.0->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 2)) (0.5.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from keras>=3.0->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 2)) (26.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (3.5.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 6)) (11.3.0)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 13))\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: PyYAML<8.0,>5.4 in /usr/local/lib/python3.12/dist-packages (from lightning->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 14)) (6.0.3)\n",
            "Collecting pytorch-lightning (from lightning->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 14))\n",
            "  Downloading pytorch_lightning-2.6.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 3)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 3)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 3)) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 3)) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 3)) (3.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 3)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 4)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 4)) (2025.3)\n",
            "Collecting cftime (from netCDF4~=1.6.0->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 6))\n",
            "  Downloading cftime-1.6.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from netCDF4~=1.6.0->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 6)) (2026.1.4)\n",
            "Requirement already satisfied: iniconfig>=1 in /usr/local/lib/python3.12/dist-packages (from pytest->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 9)) (2.3.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.12/dist-packages (from pytest->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 9)) (1.6.0)\n",
            "Requirement already satisfied: pygments>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from pytest->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 9)) (2.19.2)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.12/dist-packages (from jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (6.5.7)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.12/dist-packages (from jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (6.6.3)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.12/dist-packages (from jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (7.17.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.12/dist-packages (from jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (6.17.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.12/dist-packages (from jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (7.7.1)\n",
            "Collecting jupyterlab (from jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12))\n",
            "  Downloading jupyterlab-4.5.3-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 15)) (1.2.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 15)) (0.28.1)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 15)) (1.5.4)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 15)) (0.21.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<2028.0,>=2022.5.0->lightning->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 14)) (3.13.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 15)) (4.12.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 15)) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 15)) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface_hub->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 15)) (0.16.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 3)) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (1.8.15)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (7.4.9)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.2.1)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (26.2.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (6.5.1)\n",
            "Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (5.7.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (3.0.16)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 5)) (3.0.3)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.12/dist-packages (from jupyter-console->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (5.9.1)\n",
            "Requirement already satisfied: prompt-toolkit>=3.0.30 in /usr/local/lib/python3.12/dist-packages (from jupyter-console->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (3.0.52)\n",
            "Collecting async-lru>=1.0.0 (from jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12))\n",
            "  Downloading async_lru-2.1.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting jupyter-lsp>=2.0.0 (from jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12))\n",
            "  Downloading jupyter_lsp-2.3.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (2.14.0)\n",
            "Collecting jupyterlab-server<3,>=2.28.0 (from jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12))\n",
            "  Downloading jupyterlab_server-2.28.0-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.12/dist-packages (from jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (4.13.5)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (6.3.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (3.2.0)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.10.4)\n",
            "Requirement already satisfied: nbformat>=5.7 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (5.10.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from nbconvert->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (1.5.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (25.1.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (2.1.0)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.24.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.12/dist-packages (from notebook->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (1.3.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.0->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 2)) (4.0.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->huggingface_hub->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 15)) (8.3.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2028.0,>=2022.5.0->lightning->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 14)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2028.0,>=2022.5.0->lightning->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 14)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2028.0,>=2022.5.0->lightning->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 14)) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2028.0,>=2022.5.0->lightning->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 14)) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2028.0,>=2022.5.0->lightning->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 14)) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2028.0,>=2022.5.0->lightning->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 14)) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2028.0,>=2022.5.0->lightning->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 14)) (1.22.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (1.4.0)\n",
            "Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12))\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (4.9.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.4)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-console->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (4.5.1)\n",
            "Requirement already satisfied: jupyter-events>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.12.0)\n",
            "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.5.4)\n",
            "Requirement already satisfied: overrides>=5.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (7.7.0)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (1.9.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.12/dist-packages (from argon2-cffi->notebook->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (25.1.0)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.12/dist-packages (from jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (2.18.0)\n",
            "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12))\n",
            "  Downloading json5-0.13.0-py3-none-any.whl.metadata (36 kB)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (4.26.0)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.12/dist-packages (from jupyterlab-server<3,>=2.28.0->jupyterlab->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (2.32.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0->-r ./drive/MyDrive/proiect_ml/requirements/torch.txt (line 2)) (0.1.2)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat>=5.7->nbconvert->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (2.21.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter->-r ./drive/MyDrive/proiect_ml/requirements/basic.txt (line 12)) (0.5.3)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
            "    return func(self, options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/commands/install.py\", line 377, in run\n",
            "    requirement_set = resolver.resolve(\n",
            "                      ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 95, in resolve\n",
            "    result = self._result = resolver.resolve(\n",
            "                            ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 546, in resolve\n",
            "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 427, in resolve\n",
            "    failure_causes = self._attempt_to_pin_criterion(name)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 249, in _attempt_to_pin_criterion\n",
            "    satisfied = all(\n",
            "                ^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 250, in <genexpr>\n",
            "    self._p.is_satisfied_by(requirement=r, candidate=candidate)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/provider.py\", line 243, in is_satisfied_by\n",
            "    return requirement.is_satisfied_by(candidate)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/requirements.py\", line 119, in is_satisfied_by\n",
            "    return spec.contains(candidate.version, prereleases=True)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/packaging/specifiers.py\", line 930, in contains\n",
            "    return all(s.contains(item, prereleases=prereleases) for s in self._specs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/packaging/specifiers.py\", line 930, in <genexpr>\n",
            "    return all(s.contains(item, prereleases=prereleases) for s in self._specs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/packaging/specifiers.py\", line 563, in contains\n",
            "    return operator_callable(normalized_item, self.version)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/packaging/specifiers.py\", line 441, in _compare_greater_than_equal\n",
            "    return Version(prospective.public) >= Version(spec)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/packaging/version.py\", line 200, in __init__\n",
            "    match = self._regex.search(version)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/main.py\", line 80, in main\n",
            "    return command.main(cmd_args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 100, in main\n",
            "    return self._main(args)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 232, in _main\n",
            "    return run(options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 215, in exc_logging_wrapper\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1586, in critical\n",
            "    self._log(CRITICAL, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1684, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1700, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1762, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1028, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/utils/logging.py\", line 177, in emit\n",
            "    self.console.print(renderable, overflow=\"ignore\", crop=False, style=style)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/rich/console.py\", line 1685, in print\n",
            "    render_options = self.options.update(\n",
            "                     ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/rich/console.py\", line 983, in options\n",
            "    max_height=self.size.height,\n",
            "               ^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/rich/console.py\", line 1003, in size\n",
            "    if self.is_dumb_terminal:\n",
            "       ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/rich/console.py\", line 975, in is_dumb_terminal\n",
            "    _term = self._environ.get(\"TERM\", \"\")\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<frozen _collections_abc>\", line 807, in get\n",
            "  File \"<frozen os>\", line 709, in __getitem__\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!pip install -r ./drive/MyDrive/proiect_ml/requirements/torch.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-0b0tMziB5_b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "collapsed": true,
        "outputId": "d368831d-945e-4cc3-8e6b-8c2207f24da3"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2267674576.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinecache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   2159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2160\u001b[0m \u001b[0;31m# needs to be after the above ATen bindings so we can overwrite from Python side\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2161\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_VF\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfunctional\u001b[0m  \u001b[0;31m# usort: skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2162\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# usort: skip # noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_add_docstr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mUninitializedParameter\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mUninitializedParameter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m )\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# usort: skip # noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m from torch.nn import (\n\u001b[1;32m     10\u001b[0m     \u001b[0mattention\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mattention\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModule\u001b[0m  \u001b[0;31m# usort: skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBilinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIdentity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLazyLinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLinear\u001b[0m  \u001b[0;31m# usort: skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m from .activation import (\n\u001b[1;32m      4\u001b[0m     \u001b[0mCELU\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mELU\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prims_common\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDeviceLikeType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_dispatch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_traceable_wrapper_subclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBackwardHook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRemovableHandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import sys\n",
        "\n",
        "sys.path.append('/content/drive/MyDrive/proiect_ml')\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import importlib, linecache\n",
        "\n",
        "import torch\n",
        "from torch import optim, nn\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms, utils\n",
        "\n",
        "import tornet.data.preprocess as preprocess\n",
        "\n",
        "linecache.checkcache(preprocess.__file__)      # invalidează cache-ul de linii\n",
        "preprocess = importlib.reload(preprocess)\n",
        "\n",
        "from tornet.data.loader import read_file, TornadoDataLoader\n",
        "from tornet.data.preprocess import add_coordinates, permute_dims, remove_tilt_dim, get_shape\n",
        "from tornet.data.constants import ALL_VARIABLES\n",
        "\n",
        "data_root=r'./drive/MyDrive/proiect_ml/tornet_dataset'\n",
        "\n",
        "year = 2019\n",
        "\n",
        "catalog_path = os.path.join(data_root,'catalog.csv')\n",
        "\n",
        "# interpreteaza ca date si ore\n",
        "catalog = pd.read_csv(catalog_path,parse_dates=['start_time','end_time'])\n",
        "\n",
        "catalog['J'] = catalog['start_time'].dt.dayofyear\n",
        "catalog['r'] = catalog['J'] % 20\n",
        "catalog = catalog[catalog.start_time.dt.year == 2019]\n",
        "\n",
        "catalog_test = catalog[catalog['type'] == 'test']\n",
        "catalog_test = catalog_test.sample(frac=1,random_state=1234) # shuffles list\n",
        "\n",
        "catalog = catalog[catalog['type']=='train']\n",
        "\n",
        "catalog_train = catalog[catalog['r'] <= 13]\n",
        "catalog_train = catalog_train.sample(frac=1,random_state=1234) # shuffles list\n",
        "\n",
        "catalog_validation = catalog[(catalog['r'] > 13) & (catalog['r'] < 17)]\n",
        "catalog_validation = catalog_validation.sample(frac=1,random_state=1234) # shuffles list\n",
        "\n",
        "confirmed_number = len(catalog_train[catalog_train['category'] == 'TOR'])\n",
        "total_number = len(catalog_train)\n",
        "\n",
        "class TornadoDataset(TornadoDataLoader,Dataset):\n",
        "    pass\n",
        "\n",
        "transform = transforms.Compose([\n",
        "            lambda d: remove_tilt_dim(d)\n",
        "            ])\n",
        "\n",
        "file_list_train = [os.path.join(data_root,f) for f in catalog_train.filename]\n",
        "file_list_validation = [os.path.join(data_root,f) for f in catalog_validation.filename]\n",
        "file_list_test = [os.path.join(data_root,f) for f in catalog_test.filename]\n",
        "\n",
        "torch_ds_train = TornadoDataset(file_list_train,\n",
        "                          variables=ALL_VARIABLES,\n",
        "                          n_frames=4,\n",
        "                          tilt_last=False, # so ordering of dims is [time,tilt,az,range]\n",
        "                          transform=transform)\n",
        "\n",
        "torch_ds_validation = TornadoDataset(file_list_validation,\n",
        "                          variables=ALL_VARIABLES,\n",
        "                          n_frames=4,\n",
        "                          tilt_last=False, # so ordering of dims is [time,tilt,az,range]\n",
        "                          transform=transform)\n",
        "\n",
        "torch_ds_test = TornadoDataset(file_list_test,\n",
        "                          variables=ALL_VARIABLES,\n",
        "                          n_frames=4,\n",
        "                          tilt_last=False, # so ordering of dims is [time,tilt,az,range]\n",
        "                          transform=transform)\n",
        "\n",
        "\n",
        "batch_size=16\n",
        "\n",
        "torch_dl_train = torch.utils.data.DataLoader( torch_ds_train,\n",
        "                                        batch_size=batch_size,\n",
        "                                        num_workers=8 )\n",
        "\n",
        "torch_dl_validation = torch.utils.data.DataLoader( torch_ds_validation,\n",
        "                                        batch_size=batch_size,\n",
        "                                        num_workers=8 )\n",
        "\n",
        "torch_dl_test = torch.utils.data.DataLoader( torch_ds_test,\n",
        "                                        batch_size=batch_size,\n",
        "                                        num_workers=8 )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTh_wMXVO3ld"
      },
      "outputs": [],
      "source": [
        "from tornet.models.torch.cnn_baseline import NormalizeVariable\n",
        "from tornet.data.constants import CHANNEL_MIN_MAX\n",
        "\n",
        "def conv3d_bn_block(in_channels, out_channels, kernel_size=3, stride=1, padding='same'):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv3d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
        "        nn.BatchNorm3d(out_channels),\n",
        "        nn.ReLU(inplace=True)\n",
        "    )\n",
        "\n",
        "def conv3d_transpose_bn_block(in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
        "    return nn.Sequential(\n",
        "        nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
        "    )\n",
        "\n",
        "class TornadoLikelihood(nn.Module):\n",
        "    def __init__(self,radar_variables=ALL_VARIABLES):\n",
        "      super(TornadoLikelihood, self).__init__()\n",
        "      self.radar_variables=radar_variables\n",
        "\n",
        "      # Partea de encoder\n",
        "      self.conv_layer_encoder1 = conv3d_bn_block(in_channels=len(radar_variables), out_channels=16)\n",
        "      self.conv_layer_encoder2 = conv3d_bn_block(in_channels=16, out_channels=16)\n",
        "\n",
        "      self.max_pool_encoder1 = nn.MaxPool3d(kernel_size=(1,2,2), stride=(1,2,2))\n",
        "\n",
        "      self.conv_layer_encoder3 = conv3d_bn_block(in_channels=16, out_channels=32)\n",
        "      self.conv_layer_encoder4 = conv3d_bn_block(in_channels=32, out_channels=32)\n",
        "\n",
        "      self.max_pool_encoder2 = nn.MaxPool3d(kernel_size=(1,2,2), stride=(1,2,2))\n",
        "\n",
        "      self.conv_layer_encoder5 = conv3d_bn_block(in_channels=32, out_channels=64)\n",
        "      self.conv_layer_encoder6 = conv3d_bn_block(in_channels=64, out_channels=64)\n",
        "\n",
        "      self.max_pool_encoder3 = nn.MaxPool3d(kernel_size=2, stride=2)\n",
        "\n",
        "      self.conv_layer_encoder7 = conv3d_bn_block(in_channels=64, out_channels=128)\n",
        "      self.conv_layer_encoder8 = conv3d_bn_block(in_channels=128, out_channels=128)\n",
        "\n",
        "      self.max_pool_encoder4 = nn.MaxPool3d(kernel_size=2, stride=2)\n",
        "\n",
        "      # Partea de decoder\n",
        "      self.conv_layer_decoder1 = conv3d_bn_block(in_channels=128, out_channels=128)\n",
        "      self.conv_layer_decoder2 = conv3d_bn_block(in_channels=128, out_channels=128)\n",
        "\n",
        "      self.upsample_decoder1 = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)\n",
        "\n",
        "      self.conv_layer_decoder3 = conv3d_bn_block(in_channels=128, out_channels=64)\n",
        "      self.conv_layer_decoder4 = conv3d_bn_block(in_channels=64, out_channels=64)\n",
        "\n",
        "      self.upsample_decoder2 = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)\n",
        "\n",
        "      self.conv_layer_decoder5 = conv3d_bn_block(in_channels=64, out_channels=32)\n",
        "      self.conv_layer_decoder6 = conv3d_bn_block(in_channels=32, out_channels=32)\n",
        "\n",
        "      self.upsample_decoder3 = nn.Upsample(scale_factor=(1,2,2), mode='trilinear', align_corners=True)\n",
        "\n",
        "      self.conv_layer_decoder7 = conv3d_bn_block(in_channels=32, out_channels=16)\n",
        "      self.conv_layer_decoder8 = conv3d_bn_block(in_channels=16, out_channels=16)\n",
        "\n",
        "      self.upsample_decoder4 = nn.Upsample(scale_factor=(1,2,2), mode='trilinear', align_corners=True)\n",
        "\n",
        "      self.conv_layer_final = conv3d_transpose_bn_block(in_channels=16, out_channels=1)\n",
        "\n",
        "    def _normalize_inputs(self,data):\n",
        "        normed_data = {}\n",
        "        for v in self.radar_variables:\n",
        "            min_max = np.array(CHANNEL_MIN_MAX[v]) # [2,]\n",
        "            scale = 1/(min_max[1]-min_max[0])\n",
        "            offset = min_max[0]\n",
        "            normed_data[v] = (data[v] - offset) * scale\n",
        "\n",
        "        return normed_data\n",
        "\n",
        "    def forward(self,x):\n",
        "      \"\"\"\n",
        "      Assumes x contains radar varialbes on [batch,tilt,az,rng]\n",
        "      \"\"\"\n",
        "      # extract radar inputs\n",
        "      x = {v:x[v] for v in self.radar_variables} # each [batch,time,Az,Rng]\n",
        "      # normalize\n",
        "      x = self._normalize_inputs(x) # each [batch,time,Az,Rng]\n",
        "      # concatenate along channel (time) dim\n",
        "      x = torch.stack([x[v] for v in self.radar_variables], dim=1)\n",
        "\n",
        "      x = torch.where(torch.isnan(x),-3,x)\n",
        "\n",
        "      x = self.conv_layer_encoder1(x)\n",
        "      x = self.conv_layer_encoder2(x)\n",
        "      x = self.max_pool_encoder1(x)\n",
        "\n",
        "      x = self.conv_layer_encoder3(x)\n",
        "      x = self.conv_layer_encoder4(x)\n",
        "      x = self.max_pool_encoder2(x)\n",
        "\n",
        "      x = self.conv_layer_encoder5(x)\n",
        "      x = self.conv_layer_encoder6(x)\n",
        "      x = self.max_pool_encoder3(x)\n",
        "\n",
        "      x = self.conv_layer_encoder7(x)\n",
        "      x = self.conv_layer_encoder8(x)\n",
        "      x = self.max_pool_encoder4(x)\n",
        "\n",
        "      x = self.conv_layer_decoder1(x)\n",
        "      x = self.conv_layer_decoder2(x)\n",
        "      x = self.upsample_decoder1(x)\n",
        "\n",
        "      x = self.conv_layer_decoder3(x)\n",
        "      x = self.conv_layer_decoder4(x)\n",
        "      x = self.upsample_decoder2(x)\n",
        "\n",
        "      x = self.conv_layer_decoder5(x)\n",
        "      x = self.conv_layer_decoder6(x)\n",
        "      x = self.upsample_decoder3(x)\n",
        "\n",
        "      x = self.conv_layer_decoder7(x)\n",
        "      x = self.conv_layer_decoder8(x)\n",
        "      x = self.upsample_decoder4(x)\n",
        "\n",
        "      x = self.conv_layer_final(x)\n",
        "\n",
        "      return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KwrKOwlw8Urj"
      },
      "outputs": [],
      "source": [
        "import torchmetrics\n",
        "from torchmetrics.functional.classification import binary_auroc, binary_average_precision\n",
        "\n",
        "def accuracy(logits, y, tres):\n",
        "  correct = 0\n",
        "  for i in range(len(logits)):\n",
        "    if logits[i] >= tres and y[i] == 1:\n",
        "      correct += 1\n",
        "    elif logits[i] < tres and y[i] == 0:\n",
        "      correct += 1\n",
        "\n",
        "  return correct / float(len(y)) * 100.0\n",
        "\n",
        "def recall(logits, y, tres):\n",
        "  correct = 0\n",
        "  false_negatives = 0\n",
        "  for i in range(len(logits)):\n",
        "    if logits[i] >= tres and y[i] == 1:\n",
        "      correct += 1\n",
        "    elif logits[i] < tres and y[i] == 1:\n",
        "      false_negatives += 1\n",
        "\n",
        "  return 0.0 if correct + false_negatives == 0 else correct / (correct + false_negatives) * 100.0\n",
        "\n",
        "def precision(logits, y, tres):\n",
        "  correct = 0\n",
        "  false_positives = 0\n",
        "  for i in range(len(logits)):\n",
        "    if logits[i] >= tres and y[i] == 1:\n",
        "      correct += 1\n",
        "    elif logits[i] >= tres and y[i] == 0:\n",
        "      false_positives += 1\n",
        "\n",
        "  return 0.0 if correct + false_positives == 0 else correct / (correct + false_positives) * 100.0\n",
        "\n",
        "def f1_score(logits, y, tres):\n",
        "  p = precision(logits, y, tres)\n",
        "  r = recall(logits, y, tres)\n",
        "  return 0.0 if p + r == 0 else 2 * (p * r) / (p + r)\n",
        "\n",
        "def apply_metrics(logits, y, avg_train_loss, avg_val_loss, best_treshold):\n",
        "  acc = accuracy(logits, y, best_treshold)\n",
        "  rec = recall(logits, y, best_treshold)\n",
        "  prec = precision(logits, y, best_treshold)\n",
        "  f1 = f1_score(logits, y, best_treshold)\n",
        "  auroc = binary_auroc(logits, y)\n",
        "  auprc = binary_average_precision(logits, y)\n",
        "\n",
        "  print(f\"Accuracy: , {acc:.4f}\")\n",
        "  print(f\"Recall: , {rec:.4f}\")\n",
        "  print(f\"Precision: , {prec:.4f}\")\n",
        "  print(f\"F1 Score: , {f1:.4f}\")\n",
        "  print(f\"AUROC:  {auroc.item():.4f}\")\n",
        "  print(f\"AUPRC:  {auprc.item():.4f}\")\n",
        "\n",
        "  return {\n",
        "      'accuracy': acc,\n",
        "      'recall': rec,\n",
        "      'precision': prec,\n",
        "      'f1_score': f1,\n",
        "      'auroc': auroc.item(),\n",
        "      'auprc': auprc.item(),\n",
        "      'avg_train_loss': avg_train_loss,\n",
        "      'avg_val_loss': avg_val_loss,\n",
        "      'threshold': best_treshold\n",
        "  }\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# recall mai important! -> e mai important sa flaguiasca toate tornadele, decat sa nu emita avertizari negative\n",
        "!pip install plotnine\n",
        "import plotnine\n",
        "from plotnine import *\n",
        "from IPython.display import display\n",
        "\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "def find_best_tres(logits, y, beta):\n",
        "  precision, recall, thresholds = precision_recall_curve(y, logits)\n",
        "\n",
        "  # Plot the precision-recall curve\n",
        "  df_recall_precision = pd.DataFrame({'Precision':precision[:-1],\n",
        "                                      'Recall':recall[:-1],\n",
        "                                      'Threshold':thresholds})\n",
        "  df_recall_precision.head()\n",
        "\n",
        "  plotnine.options.figure_size = (8, 4.8)\n",
        "\n",
        "  # Creat a data viz\n",
        "  plot1 = (\n",
        "      ggplot(data = df_recall_precision) +\n",
        "      geom_point(aes(x='Recall', y='Precision'), size=0.4) +\n",
        "      geom_line(aes(x='Recall', y='Precision')) +\n",
        "      labs(title='Recall Precision Curve') +\n",
        "      xlab('Recall') +\n",
        "      ylab('Precision') +\n",
        "      theme_minimal()\n",
        "  )\n",
        "  display(plot1)\n",
        "\n",
        "  precision = precision[:-1]\n",
        "  recall = recall[:-1]\n",
        "\n",
        "  den = (beta**2)*precision + recall\n",
        "  fbeta_score = np.where(den > 0, (1 + beta**2) * precision * recall / den, -np.inf)\n",
        "\n",
        "  # Find the optimal threshold\n",
        "  index = np.argmax(fbeta_score)\n",
        "  thresholdOpt = round(thresholds[index], ndigits = 4)\n",
        "  fscoreOpt = round(fbeta_score[index], ndigits = 4)\n",
        "  recallOpt = round(recall[index], ndigits = 4)\n",
        "  precisionOpt = round(precision[index], ndigits = 4)\n",
        "  print('Best Threshold: {} with F-Score: {}'.format(thresholdOpt, fscoreOpt))\n",
        "  print('Recall: {}, Precision: {}'.format(recallOpt, precisionOpt))\n",
        "\n",
        "  plotnine.options.figure_size = (8, 4.8)\n",
        "\n",
        "  # Create a data viz\n",
        "  plot2 = (\n",
        "    ggplot(data = df_recall_precision)+\n",
        "    geom_point(aes(x = 'Recall',\n",
        "                    y = 'Precision'),\n",
        "                size = 0.4)+\n",
        "    # Best threshold\n",
        "    geom_point(aes(x = recallOpt,\n",
        "                    y = precisionOpt),\n",
        "                color = '#981220',\n",
        "                size = 4)+\n",
        "    geom_line(aes(x = 'Recall',\n",
        "                  y = 'Precision'))+\n",
        "    # Annotate the text\n",
        "    geom_text(aes(x = recallOpt,\n",
        "                  y = precisionOpt),\n",
        "              label = 'Optimal threshold \\n for class: {}'.format(thresholdOpt),\n",
        "              nudge_x = 0.18,\n",
        "              nudge_y = 0,\n",
        "              size = 10,\n",
        "              fontstyle = 'italic')+\n",
        "    labs(title = 'Recall Precision Curve')+\n",
        "    xlab('Recall')+\n",
        "    ylab('Precision')+\n",
        "    theme_minimal()\n",
        "  )\n",
        "\n",
        "  display(plot2)\n",
        "\n",
        "  return thresholdOpt\n"
      ],
      "metadata": {
        "id": "HQrz833PWpQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from time import time\n",
        "import logging\n",
        "\n",
        "training_logs = []\n",
        "class TrainingLogger:\n",
        "    def __init__(self):\n",
        "        logging.basicConfig(level=logging.INFO, format='%(message)s', filename='/content/drive/MyDrive/proiect_ml/training.log', filemode='a')\n",
        "\n",
        "    def on_epoch_begin(self, epoch):\n",
        "        self.epoch_start_time = time()\n",
        "        logging.info(f\"Epoch {epoch + 1} starting.\")\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        elapsed_time = time() - self.epoch_start_time\n",
        "        logging.info(f\"Epoch {epoch + 1} finished in {elapsed_time:.2f} seconds.\")\n",
        "        logs['epoch_time'] = elapsed_time  # Add epoch time to logs\n",
        "        training_logs.append(logs)  # Collect training logs\n",
        "        logging.info(f\"Epoch {epoch + 1}: Val loss = {logs['avg_val_loss']:.4f}, Accuracy = {logs['accuracy']:.4f}, Recall = {logs['recall']:.4f}, Precision = {logs['precision']:.4f}, F1 = {logs['f1_score']:.4f}, AUROC = {logs['auroc']:.4f}, AUPRC = {logs['auprc']:.4f}\")\n"
      ],
      "metadata": {
        "id": "1ebH4pzJ9CjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JIJRviy1KmYa"
      },
      "outputs": [],
      "source": [
        "from torch.optim import Optimizer\n",
        "\n",
        "class RMSpropFromScratch(Optimizer):\n",
        "    def __init__(self, params, lr=1e-3, alpha=0.99, eps=1e-8,\n",
        "                 weight_decay=0.0, momentum=0.0, centered=False):\n",
        "\n",
        "        defaults = dict(lr=lr, alpha=alpha, eps=eps,\n",
        "                        weight_decay=weight_decay, momentum=momentum,\n",
        "                        centered=centered)\n",
        "        super().__init__(params, defaults)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def step(self, closure=None):\n",
        "        loss = None\n",
        "\n",
        "        if closure is not None:\n",
        "            with torch.enable_grad():\n",
        "                loss = closure()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            lr = group['lr']\n",
        "            alpha = group['alpha']\n",
        "            eps = group['eps']\n",
        "            wd = group['weight_decay']\n",
        "\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "\n",
        "                grad = p.grad\n",
        "\n",
        "                # weight decay: g <- g + wd * w\n",
        "                if wd != 0.0:\n",
        "                    grad = grad.add(p, alpha=wd)\n",
        "\n",
        "                state = self.state[p]\n",
        "                # init state\n",
        "                if len(state) == 0:\n",
        "                    state[\"square_avg\"] = torch.zeros_like(p, memory_format=torch.preserve_format)  # E[g^2]\n",
        "\n",
        "                    if group[\"momentum\"] > 0:\n",
        "                      state[\"momentum_buffer\"] = torch.zeros_like(p, memory_format=torch.preserve_format)\n",
        "\n",
        "                    if group[\"centered\"]:\n",
        "                      state[\"grad_avg\"] = torch.zeros_like(p, memory_format=torch.preserve_format)  # E[g]\n",
        "\n",
        "                square_avg = state['square_avg']\n",
        "                square_avg.mul_(alpha).addcmul_(grad, grad, value=1 - alpha)\n",
        "\n",
        "                if group['centered']:\n",
        "                    grad_avg = state['grad_avg']\n",
        "                    grad_avg.mul_(alpha).add_(grad, alpha=1 - alpha)\n",
        "                    # var ≈ E[g^2] - (E[g])^2\n",
        "                    avg = square_avg.addcmul(grad_avg, grad_avg, value=-1).sqrt_()\n",
        "                else:\n",
        "                    avg = square_avg.sqrt()\n",
        "\n",
        "                avg = avg.add_(eps)\n",
        "\n",
        "                if group['momentum'] > 0.0:\n",
        "                    buf = state['momentum_buffer']\n",
        "                    buf.mul_(['momentum']).addcdiv_(grad, avg)\n",
        "                    p.add_(buf, alpha=-lr)\n",
        "                else:\n",
        "                    p.addcdiv_(grad, avg, value=-lr)\n",
        "\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import logging\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from time import time\n",
        "\n",
        "from typing import Dict, List, Tuple, Any\n",
        "import numpy as np\n",
        "\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import torch.nn.functional as F\n",
        "\n",
        "num_epochs = 15\n",
        "\n",
        "best_val = 10\n",
        "\n",
        "model = TornadoLikelihood()\n",
        "\n",
        "pos_weight = torch.tensor([(total_number - confirmed_number)/confirmed_number])  # weight asociat cu clasa pozitiva\n",
        "loss_f = nn.BCEWithLogitsLoss(pos_weight=pos_weight)  # daca w_p > 1 => favorizeaza recall, invers => precision\n",
        "\n",
        "optimizer = RMSpropFromScratch(model.parameters(), lr=1e-3)\n",
        "\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n",
        "\n",
        "# TensorBoard setup\n",
        "writer = SummaryWriter('/content/drive/MyDrive/proiect_ml/summary')\n",
        "\n",
        "ckpt_path = \"/content/drive/MyDrive/proiect_ml/checkpoints/best.pth\"\n",
        "ckpt = torch.load(ckpt_path)\n",
        "\n",
        "model.load_state_dict(ckpt[\"model_state\"])\n",
        "optimizer.load_state_dict(ckpt[\"optimizer_state\"])\n",
        "scheduler.load_state_dict(ckpt[\"scheduler_state\"])\n",
        "\n",
        "start_epoch = int(ckpt[\"epoch\"]) + 1   # <- va fi 1\n",
        "best_val = float(ckpt.get(\"val_loss\", 1e9))\n",
        "\n",
        "print(f\"Reluare din {ckpt_path} | start_epoch={start_epoch} | best_val={best_val:.4f}\")\n",
        "\n",
        "best_treshold = 0.6\n",
        "\n",
        "avg_val_loss = best_val\n",
        "avg_train_loss = 0.0"
      ],
      "metadata": {
        "id": "1D03Yu7yulR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Ii192qVskex"
      },
      "outputs": [],
      "source": [
        "\n",
        "patience = 5\n",
        "patience_counter = 0\n",
        "\n",
        "callback = TrainingLogger()\n",
        "\n",
        "# Training loop\n",
        "total_step = len(torch_dl_train)\n",
        "\n",
        "eps = 0.05\n",
        "\n",
        "for epoch in range(start_epoch, num_epochs):\n",
        "    callback.on_epoch_begin(epoch)\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "\n",
        "    for i, batch in enumerate(torch_dl_train):\n",
        "        y = torch.squeeze(batch.pop('label'))\n",
        "        y_float = y[:, -1].float()\n",
        "\n",
        "        # De ce label smoothing? Nu e niciodata 100% ca e tornada\n",
        "        y_smooth = y_float * (1 - 2*eps) + eps\n",
        "\n",
        "        # Forward pass\n",
        "        logits = model(batch) # [batch,1,T,L,W]\n",
        "        logits = F.max_pool3d(logits, kernel_size=logits.size()[2:]) # [batch,1,1,1,1]\n",
        "        logits = torch.squeeze(logits) # [batch,1] for binary classifications\n",
        "        loss = loss_f(logits, y_smooth)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        if (i+1) % 10 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{total_step}], Loss: {loss.item():.4f}')\n",
        "\n",
        "    # Calculate average training loss for the epoch\n",
        "    avg_train_loss = train_loss / len(torch_dl_train)\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Average Training Loss: {avg_train_loss:.4f}')\n",
        "    writer.add_scalar('training loss', avg_train_loss, epoch)\n",
        "\n",
        "    ckpt_path = f\"/content/drive/MyDrive/proiect_ml/checkpoints/epoch_{epoch+1:03d}.pth\"\n",
        "    torch.save({\n",
        "        \"epoch\": epoch,\n",
        "        \"model_state\": model.state_dict(),\n",
        "        \"optimizer_state\": optimizer.state_dict(),\n",
        "        \"scheduler_state\": scheduler.state_dict(),\n",
        "        \"val_loss\": avg_train_loss,\n",
        "    }, ckpt_path)\n",
        "\n",
        "    # Validation\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        val_loss = 0.0\n",
        "        for i, batch in enumerate(torch_dl_validation):\n",
        "            y = torch.squeeze(batch.pop('label'))\n",
        "            y_float = y[:, -1].float()\n",
        "            y_int = y[:, -1].long()\n",
        "\n",
        "            # Forward pass\n",
        "            logits = model(batch) # [batch,1,T,L,W]\n",
        "            logits = F.max_pool3d(logits, kernel_size=logits.size()[2:]) # [batch,1,1,1,1]\n",
        "            logits = torch.squeeze(logits) # [batch,1] for binary classifications\n",
        "            loss = loss_f(logits, y_float)\n",
        "\n",
        "            all_probs.append(torch.sigmoid(logits))\n",
        "            all_labels.append(y_int)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "\n",
        "        avg_val_loss = val_loss / len(torch_dl_validation)\n",
        "        writer.add_scalar('validation loss', avg_val_loss, epoch)\n",
        "        all_probs = torch.cat(all_probs, dim = 0)\n",
        "        all_labels = torch.cat(all_labels, dim = 0)\n",
        "\n",
        "    if avg_val_loss < best_val:\n",
        "        best_val = avg_val_loss\n",
        "        best_path = \"/content/drive/MyDrive/proiect_ml/checkpoints/best.pth\"\n",
        "        torch.save({\n",
        "            \"epoch\": epoch,\n",
        "            \"model_state\": model.state_dict(),\n",
        "            \"optimizer_state\": optimizer.state_dict(),\n",
        "            \"scheduler_state\": scheduler.state_dict(),\n",
        "            \"val_loss\": avg_val_loss,\n",
        "        }, best_path)\n",
        "        print(f\"[Epoch {epoch+1}] Best model salvat la {best_path} (val_loss={best_val:.4f})\")\n",
        "\n",
        "        patience_counter = 0\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Early stopping triggered at epoch {epoch+1}.\")\n",
        "            break\n",
        "\n",
        "    # Learning rate scheduling\n",
        "    scheduler.step(avg_val_loss)\n",
        "\n",
        "    logs = apply_metrics(all_probs, all_labels, avg_train_loss, avg_val_loss, best_treshold)\n",
        "\n",
        "    best_treshold = find_best_tres(all_probs, all_labels, 2)\n",
        "\n",
        "    callback.on_epoch_end(epoch, logs)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Final test\n",
        "\n",
        "all_probs = []\n",
        "all_labels = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  for i, batch in enumerate(torch_dl_test):\n",
        "        y = torch.squeeze(batch.pop('label'))\n",
        "        y_float = y[:, -1].float()\n",
        "        y_int = y[:, -1].long()\n",
        "\n",
        "        # Forward pass\n",
        "        logits = model(batch) # [batch,1,T,L,W]\n",
        "        logits = F.max_pool3d(logits, kernel_size=logits.size()[2:]) # [batch,1,1,1,1]\n",
        "        logits = torch.squeeze(logits) # [batch,1] for binary classifications\n",
        "\n",
        "        all_probs.append(torch.sigmoid(logits))\n",
        "        all_labels.append(y_int)\n",
        "\n",
        "all_probs = torch.cat(all_probs, dim = 0)\n",
        "all_labels = torch.cat(all_labels, dim = 0)\n",
        "logs = apply_metrics(all_probs, all_labels, avg_train_loss, avg_val_loss, best_treshold)\n",
        "\n",
        "callback.on_epoch_end(epoch, logs)\n",
        "\n",
        "writer.close()"
      ],
      "metadata": {
        "id": "Pl_hxRZkCtz8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1TmDWD6ZoNrM7k3y6VjaTxove4X-58koB",
      "authorship_tag": "ABX9TyNeAgRayGpkumkeSWZCz0M5",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}